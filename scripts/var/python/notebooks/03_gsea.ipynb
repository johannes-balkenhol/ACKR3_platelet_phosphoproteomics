{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab7eb6f-645d-4590-90df-f87f2059c7d5",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9990c0d9-9df9-4cec-9f69-a987ab8cc8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP53 Entrez ID: None\n",
      "TP53 UniProt: None\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# --- paths ---\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "DATA_PROCESSED_DIR = BASE / \"data\" / \"processed_data\"\n",
    "DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "H5AD_OUT   = DATA_PROCESSED_DIR / \"host_bulk_fractional_counts_ensembl.h5ad\"\n",
    "DICT_OUT   = DATA_PROCESSED_DIR / \"ensembl_mappings.pkl\"\n",
    "\n",
    "\n",
    "# load AnnData\n",
    "adata_ens = ad.read_h5ad(H5AD_OUT)\n",
    "\n",
    "# load dictionaries\n",
    "with open(DICT_OUT, \"rb\") as f:\n",
    "    maps = pickle.load(f)\n",
    "\n",
    "ens2entrez = maps[\"ens2entrez\"]\n",
    "ens2uniprot = maps[\"ens2uniprot\"]\n",
    "\n",
    "print(\"TP53 Entrez ID:\", ens2entrez.get(\"ENSG00000141510\"))\n",
    "print(\"TP53 UniProt:\", ens2uniprot.get(\"ENSG00000141510\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "999906f1-2e28-409a-9385-ed5be48efd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ENSG00000278267.1': '102466751', 'ENSG00000284332.1': '100302278', 'ENSG00000237613.2': '645520', 'ENSG00000268020.3': '79504', 'ENSG00000240361.2': '403263', 'ENSG00000186092.6': '79501', 'ENSG00000233750.3': '100420257', 'ENSG00000222623.1': '124906683', 'ENSG00000273874.1': '102465909', 'ENSG00000228463.10': '728481'}\n",
      "{'ENSG00000186092.6': 'Q8NH21', 'ENSG00000284733.1': 'Q6IEY1', 'ENSG00000284662.1': 'Q6IEY1', 'ENSG00000187634.12': 'Q96NU1', 'ENSG00000188976.11': 'Q9Y3T9', 'ENSG00000187961.14': 'Q6TDP4', 'ENSG00000187583.11': 'Q494U1', 'ENSG00000187642.9': 'Q5SV97', 'ENSG00000188290.11': 'Q9HCC6', 'ENSG00000187608.10': 'P05161'}\n"
     ]
    }
   ],
   "source": [
    "# filter out None/NaN/empty\n",
    "ens2entrez  = {k: v for k, v in ens2entrez.items() if v is not None and str(v) != \"nan\"}\n",
    "ens2uniprot = {k: v for k, v in ens2uniprot.items() if v not in [None, [], \"nan\"]}\n",
    "\n",
    "# print first 5 entries\n",
    "print(dict(list(ens2entrez.items())[:10]))\n",
    "print(dict(list(ens2uniprot.items())[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "076a80fc-abda-4a7f-a841-db147a20f2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 12 × 67016\n",
       "    obs: 'condition', 'tissue', 'replicate'\n",
       "    var: 'ensembl_core', 'gene_symbol'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b94a36-88fc-4d11-ae63-d886de5eb60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ENSG00000223972.5', 'ENSG00000227232.5', 'ENSG00000278267.1',\n",
       "       'ENSG00000243485.5', 'ENSG00000284332.1', 'ENSG00000237613.2',\n",
       "       'ENSG00000268020.3', 'ENSG00000240361.2', 'ENSG00000186092.6',\n",
       "       'ENSG00000238009.6',\n",
       "       ...\n",
       "       'ENSG00000273739.1', 'ENSG00000276700.1', 'ENSG00000276312.1',\n",
       "       'ENSG00000275757.1', 'ENSG00000278573.1', 'ENSG00000276017.1',\n",
       "       'ENSG00000278817.1', 'ENSG00000277196.4', 'ENSG00000278625.1',\n",
       "       'ENSG00000277374.1'],\n",
       "      dtype='object', length=67016)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_ens.var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c9e5f-f50c-4fd8-8bf4-40c5e2933df8",
   "metadata": {},
   "source": [
    "# Perform GSEA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2dc0ad-acf1-4fdb-8957-bc082070d24d",
   "metadata": {},
   "source": [
    "## Reactome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f26ef27-e8ce-4a25-8ea7-68f354368d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Bt_vs_Mock: 60,966 ranked symbols -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Bt_vs_Mock.rnk\n",
      "[OK] Cd_vs_Mock: 60,966 ranked symbols -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Cd_vs_Mock.rnk\n",
      "[OK] Co_vs_Mock: 60,966 ranked symbols -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Co_vs_Mock.rnk\n",
      "[OK] Bt_vs_Cd: 60,966 ranked symbols -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Bt_vs_Cd.rnk\n",
      "[OK] Bt_vs_Co: 60,966 ranked symbols -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Bt_vs_Co.rnk\n",
      "[OK] Cd_vs_Co: 60,966 ranked symbols -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Cd_vs_Co.rnk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/1254546859.py:70: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 15:37:48,048 [WARNING] Duplicated values found in preranked stats: 42.07% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n",
      "/tmp/ipykernel_1853692/1254546859.py:70: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 15:39:29,438 [WARNING] Duplicated values found in preranked stats: 42.06% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Reactome GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Bt_vs_Mock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/1254546859.py:70: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 15:41:08,880 [WARNING] Duplicated values found in preranked stats: 42.11% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Reactome GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Cd_vs_Mock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/1254546859.py:70: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 15:42:42,281 [WARNING] Duplicated values found in preranked stats: 42.33% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Reactome GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Co_vs_Mock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/1254546859.py:70: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 15:44:08,818 [WARNING] Duplicated values found in preranked stats: 42.49% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Reactome GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Bt_vs_Cd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/1254546859.py:70: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 15:45:47,520 [WARNING] Duplicated values found in preranked stats: 42.31% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Reactome GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Bt_vs_Co\n",
      "[OK] Reactome GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/reactome/Cd_vs_Co\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'FDR_q'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/gsea/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FDR_q'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c, df \u001b[38;5;129;01min\u001b[39;00m all_res\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 91\u001b[0m         keep\u001b[38;5;241m.\u001b[39mupdate(df\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFDR_q\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTerm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[WARN] No Reactome pathways at FDR<0.05. Lower threshold or check inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/gsea/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniforge3/envs/gsea/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FDR_q'"
     ]
    }
   ],
   "source": [
    "# --- Reactome GSEA using gseapy (symbols) + NES heatmap ---\n",
    "from pathlib import Path\n",
    "import re, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, leaves_list\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Paths\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "ANALYSIS_DIR = BASE / \"analysis\"\n",
    "DE_DIR   = ANALYSIS_DIR / \"DE\"\n",
    "GSEA_DIR = ANALYSIS_DIR / \"GSEA\" / \"reactome\"\n",
    "FIG_DIR  = ANALYSIS_DIR / \"figures\"\n",
    "GSEA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Contrasts present from your Python-only DE\n",
    "contrasts = [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\",\"Bt_vs_Cd\",\"Bt_vs_Co\",\"Cd_vs_Co\"]\n",
    "\n",
    "def strip_ver(x: str) -> str:\n",
    "    return re.sub(r\"\\.\\d+$\", \"\", x)\n",
    "\n",
    "# ---------- Build Ensembl(core) -> SYMBOL map from adata_ens.var ----------\n",
    "# prefer 'gene_symbol', else 'gene_symbols'\n",
    "sym_col = \"gene_symbol\" if \"gene_symbol\" in adata_ens.var.columns else (\n",
    "          \"gene_symbols\" if \"gene_symbols\" in adata_ens.var.columns else None)\n",
    "if sym_col is None:\n",
    "    raise ValueError(\"No 'gene_symbol' or 'gene_symbols' in adata_ens.var\")\n",
    "\n",
    "if \"ensembl_core\" in adata_ens.var.columns:\n",
    "    core_ids = adata_ens.var[\"ensembl_core\"].astype(str).values\n",
    "else:\n",
    "    core_ids = pd.Index(adata_ens.var_names.astype(str)).map(strip_ver).values\n",
    "\n",
    "ens2sym = pd.Series(adata_ens.var[sym_col].astype(str).values, index=core_ids)\n",
    "\n",
    "# ---------- Build preranked lists (t-stat) per contrast ----------\n",
    "rank_files = {}\n",
    "for c in contrasts:\n",
    "    f = DE_DIR / f\"python_voomlite_{c}.csv\"\n",
    "    if not f.exists():\n",
    "        print(f\"[WARN] missing DE file: {f} — skipping\")\n",
    "        continue\n",
    "    df = pd.read_csv(f)\n",
    "    df[\"gene\"] = df[\"gene\"].astype(str)\n",
    "    df[\"gene_core\"] = df[\"gene\"].map(strip_ver)\n",
    "    # map to symbol\n",
    "    df[\"symbol\"] = df[\"gene_core\"].map(ens2sym)\n",
    "\n",
    "    # ranking metric: t-stat preferred; fallback to signed -log10(p)\n",
    "    if \"t\" in df.columns and np.isfinite(df[\"t\"]).any():\n",
    "        df[\"score\"] = df[\"t\"].astype(float)\n",
    "    else:\n",
    "        df[\"score\"] = np.sign(df[\"logFC\"].astype(float)) * (-np.log10(np.clip(df[\"pval\"].astype(float), 1e-300, 1.0)))\n",
    "\n",
    "    rnk = df.loc[df[\"symbol\"].notna() & np.isfinite(df[\"score\"]), [\"symbol\",\"score\"]].copy()\n",
    "    rnk = rnk.sort_values(\"score\", key=lambda x: x.abs(), ascending=False).drop_duplicates(\"symbol\")\n",
    "    rnk = rnk.sort_values(\"score\", ascending=False)\n",
    "\n",
    "    out_rnk = GSEA_DIR / f\"{c}.rnk\"\n",
    "    rnk.to_csv(out_rnk, sep=\"\\t\", header=False, index=False)\n",
    "    rank_files[c] = out_rnk\n",
    "    print(f\"[OK] {c}: {len(rnk):,} ranked symbols -> {out_rnk}\")\n",
    "\n",
    "# ---------- Run gseapy prerank on Reactome ----------\n",
    "import gseapy as gp\n",
    "\n",
    "all_res = {}\n",
    "for c, rnk_path in rank_files.items():\n",
    "    outdir = GSEA_DIR / c\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    prer = gp.prerank(\n",
    "        rnk=str(rnk_path),\n",
    "        gene_sets=\"Reactome_2022\",   # Enrichr Reactome (symbols)\n",
    "        processes=4,\n",
    "        permutation_num=1000,\n",
    "        min_size=10, max_size=1000,\n",
    "        seed=42,\n",
    "        outdir=str(outdir),\n",
    "        format=\"png\"                 # enrichment plots saved per pathway\n",
    "    )\n",
    "    res2d = prer.res2d.copy()\n",
    "    res2d.rename(columns={\"fdr\":\"FDR_q\"}, inplace=True)\n",
    "    res2d.to_csv(outdir / \"gsea_reactome_results.csv\", index=False)\n",
    "    all_res[c] = res2d\n",
    "    print(f\"[OK] Reactome GSEA saved -> {outdir}\")\n",
    "\n",
    "# ---------- Build NES matrix & plot clustered heatmap (pathways x contrasts) ----------\n",
    "# keep pathways significant in ≥1 contrast (FDR_q < 0.05)\n",
    "keep = set()\n",
    "for c, df in all_res.items():\n",
    "    if not df.empty:\n",
    "        keep.update(df.loc[df[\"FDR_q\"] < 0.05, \"Term\"].tolist())\n",
    "\n",
    "if not keep:\n",
    "    print(\"[WARN] No Reactome pathways at FDR<0.05. Lower threshold or check inputs.\")\n",
    "else:\n",
    "    pathways = sorted(keep)\n",
    "    NES = pd.DataFrame(index=pathways, columns=contrasts, dtype=float)\n",
    "    FDR = pd.DataFrame(index=pathways, columns=contrasts, dtype=float)\n",
    "    for c in contrasts:\n",
    "        if c in all_res and not all_res[c].empty:\n",
    "            df = all_res[c].set_index(\"Term\")\n",
    "            NES.loc[pathways, c] = df.reindex(pathways)[\"NES\"].values\n",
    "            FDR.loc[pathways, c] = df.reindex(pathways)[\"FDR_q\"].values\n",
    "\n",
    "    # replace inf/nan\n",
    "    NES = NES.astype(float).fillna(0.0).clip(-3.5, 3.5)  # clamp for color scale stability\n",
    "\n",
    "    # cluster rows (pathways) and columns (contrasts) by correlation distance\n",
    "    def corr_linkage(mat, axis=0, method=\"average\"):\n",
    "        # axis=0 -> rows; axis=1 -> cols\n",
    "        X = mat if axis==0 else mat.T\n",
    "        C = np.corrcoef(X)\n",
    "        D = np.clip(1 - C, 0, 2)\n",
    "        return linkage(squareform(D, checks=False), method=method)\n",
    "\n",
    "    row_link = corr_linkage(NES.values, axis=0, method=\"average\")\n",
    "    col_link = corr_linkage(NES.values, axis=1, method=\"average\")\n",
    "    row_ord  = leaves_list(row_link)\n",
    "    col_ord  = leaves_list(col_link)\n",
    "\n",
    "    NES_ord = NES.values[row_ord][:, col_ord]\n",
    "    row_lbl = [NES.index[i] for i in row_ord]\n",
    "    col_lbl = [NES.columns[i] for i in col_ord]\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(max(8, 0.45*len(col_lbl)+3), max(8, 0.22*len(row_lbl)+3)))\n",
    "    # top dendrogram\n",
    "    ax_top = plt.axes([0.28, 0.90, 0.62, 0.08])\n",
    "    dendrogram(col_link, ax=ax_top, no_labels=True); ax_top.axis(\"off\")\n",
    "    # left dendrogram\n",
    "    ax_left = plt.axes([0.07, 0.20, 0.20, 0.70])\n",
    "    dendrogram(row_link, ax=ax_left, orientation=\"right\", no_labels=True); ax_left.axis(\"off\")\n",
    "    # heatmap\n",
    "    ax = plt.axes([0.28, 0.20, 0.62, 0.70])\n",
    "    im = ax.imshow(NES_ord, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    ax.set_xticks(range(len(col_lbl))); ax.set_xticklabels(col_lbl, rotation=45, ha=\"right\", fontsize=9)\n",
    "    ax.set_yticks(range(len(row_lbl))); ax.set_yticklabels(row_lbl, fontsize=8)\n",
    "    ax.set_title(\"Reactome GSEA (NES, FDR<0.05 pathways)\")\n",
    "    # colorbar\n",
    "    cax = plt.axes([0.91, 0.20, 0.02, 0.70])\n",
    "    cb = plt.colorbar(im, cax=cax); cb.set_label(\"NES\")\n",
    "\n",
    "    out_png = FIG_DIR / \"reactome_gsea_NES_heatmap.png\"\n",
    "    plt.savefig(out_png, dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "    NES.to_csv(GSEA_DIR / \"reactome_NES_matrix.csv\")\n",
    "    FDR.to_csv(GSEA_DIR / \"reactome_FDR_matrix.csv\")\n",
    "    print(f\"[OK] NES heatmap -> {out_png}\")\n",
    "    print(f\"[OK] NES/FDR matrices -> {GSEA_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756794b6-d385-459c-8dec-eccd5ff1790a",
   "metadata": {},
   "source": [
    "## KEGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a1cbb60-e325-4d89-a384-950ca10d903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OPTIONAL: KEGG (Entrez) or HALLMARK (symbols) GSEA setup ---\n",
    "import re, numpy as np, pandas as pd, gseapy as gp\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "DE_DIR   = BASE / \"analysis\" / \"DE\"\n",
    "GSEA_DIR = BASE / \"analysis\" / \"GSEA\"\n",
    "(GSEA_DIR / \"kegg\").mkdir(parents=True, exist_ok=True)\n",
    "(GSEA_DIR / \"hallmark\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def strip_ver(x: str) -> str:\n",
    "    return re.sub(r\"\\.\\d+$\", \"\", x)\n",
    "\n",
    "# Clean your dictionaries (you already did this upstream)\n",
    "# ens2entrez: keys are Ensembl WITH version (e.g., ENSG... .13) -> Entrez (string)\n",
    "# ens2uniprot: (not used here but handy if a library requires UniProt)\n",
    "def run_collection(collection_name: str, id_type: str, out_subdir: str):\n",
    "    # id_type: \"entrez\" or \"symbol\"\n",
    "    outbase = GSEA_DIR / out_subdir\n",
    "    rank_files = {}\n",
    "    for c in [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\",\"Bt_vs_Cd\",\"Bt_vs_Co\",\"Cd_vs_Co\"]:\n",
    "        f = DE_DIR / f\"python_voomlite_{c}.csv\"\n",
    "        if not f.exists(): \n",
    "            print(f\"[WARN] missing {f}\"); \n",
    "            continue\n",
    "        df = pd.read_csv(f)\n",
    "        df[\"gene\"] = df[\"gene\"].astype(str)\n",
    "\n",
    "        if id_type == \"entrez\":\n",
    "            # map Ensembl(with version) -> Entrez directly via your dict\n",
    "            # drop genes without Entrez\n",
    "            df[\"id\"] = df[\"gene\"].map(ens2entrez).astype(str)\n",
    "        elif id_type == \"symbol\":\n",
    "            # use symbols from adata (as in the Reactome block)\n",
    "            if \"ensembl_core\" in adata_ens.var.columns:\n",
    "                core_ids = adata_ens.var[\"ensembl_core\"].astype(str).values\n",
    "            else:\n",
    "                core_ids = pd.Index(adata_ens.var_names.astype(str)).map(strip_ver).values\n",
    "            sym_col = \"gene_symbol\" if \"gene_symbol\" in adata_ens.var.columns else (\n",
    "                      \"gene_symbols\" if \"gene_symbols\" in adata_ens.var.columns else None)\n",
    "            assert sym_col is not None, \"No symbols found in adata_ens.var\"\n",
    "            ens2sym = pd.Series(adata_ens.var[sym_col].astype(str).values, index=core_ids)\n",
    "            df[\"id\"] = df[\"gene\"].map(strip_ver).map(ens2sym)\n",
    "        else:\n",
    "            raise ValueError(\"id_type must be 'entrez' or 'symbol'\")\n",
    "\n",
    "        # rank: t-stat preferred\n",
    "        score = df[\"t\"] if \"t\" in df.columns else np.sign(df[\"logFC\"]) * (-np.log10(np.clip(df[\"pval\"], 1e-300, 1.0)))\n",
    "        rnk = pd.DataFrame({\"id\": df[\"id\"], \"score\": pd.to_numeric(score, errors=\"coerce\")})\n",
    "        rnk = rnk.dropna().astype({\"id\": str, \"score\": float})\n",
    "        rnk = rnk[~rnk[\"id\"].isin([\"\", \"nan\", \"None\"])]\n",
    "        rnk = rnk.sort_values(\"score\", key=lambda x: x.abs(), ascending=False).drop_duplicates(\"id\")\n",
    "        rnk = rnk.sort_values(\"score\", ascending=False)\n",
    "\n",
    "        out_rnk = outbase / f\"{c}.rnk\"\n",
    "        rnk.to_csv(out_rnk, sep=\"\\t\", header=False, index=False)\n",
    "        rank_files[c] = out_rnk\n",
    "        print(f\"[OK] {collection_name} RNK for {c}: {len(rnk)} ids -> {out_rnk}\")\n",
    "\n",
    "    # Run gseapy.prerank\n",
    "    for c, rnk in rank_files.items():\n",
    "        outdir = outbase / c; outdir.mkdir(parents=True, exist_ok=True)\n",
    "        prer = gp.prerank(\n",
    "            rnk=str(rnk),\n",
    "            gene_sets=collection_name,   # e.g., \"KEGG_2021_Human\" or \"MSigDB_Hallmark_2020\"\n",
    "            processes=4,\n",
    "            permutation_num=1000,\n",
    "            min_size=10, max_size=1000,\n",
    "            seed=42,\n",
    "            outdir=str(outdir),\n",
    "            format=\"png\"\n",
    "        )\n",
    "        res = prer.res2d.copy()\n",
    "        res.rename(columns={\"fdr\":\"FDR_q\"}, inplace=True)\n",
    "        res.to_csv(outdir / f\"gsea_{out_subdir}_results.csv\", index=False)\n",
    "        print(f\"[OK] {collection_name} for {c} -> {outdir}\")\n",
    "\n",
    "# Example calls:\n",
    "# KEGG via Entrez:\n",
    "# run_collection(collection_name=\"KEGG_2021_Human\", id_type=\"entrez\",  out_subdir=\"kegg\")\n",
    "\n",
    "# HALLMARK via symbols:\n",
    "# run_collection(collection_name=\"MSigDB_Hallmark_2020\", id_type=\"symbol\", out_subdir=\"hallmark\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b0bf235-930e-48fc-b14d-e160fa4e74ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] KEGG_2021_Human RNK for Bt_vs_Mock: 60966 ids -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Bt_vs_Mock.rnk\n",
      "[OK] KEGG_2021_Human RNK for Cd_vs_Mock: 60966 ids -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Cd_vs_Mock.rnk\n",
      "[OK] KEGG_2021_Human RNK for Co_vs_Mock: 60966 ids -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Co_vs_Mock.rnk\n",
      "[OK] KEGG_2021_Human RNK for Bt_vs_Cd: 60966 ids -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Bt_vs_Cd.rnk\n",
      "[OK] KEGG_2021_Human RNK for Bt_vs_Co: 60966 ids -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Bt_vs_Co.rnk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/3854109486.py:63: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:16:50,230 [WARNING] Duplicated values found in preranked stats: 42.07% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] KEGG_2021_Human RNK for Cd_vs_Co: 60966 ids -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Cd_vs_Co.rnk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/3854109486.py:63: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:17:25,628 [WARNING] Duplicated values found in preranked stats: 42.06% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] KEGG_2021_Human for Bt_vs_Mock -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Bt_vs_Mock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/3854109486.py:63: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:17:59,534 [WARNING] Duplicated values found in preranked stats: 42.11% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] KEGG_2021_Human for Cd_vs_Mock -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Cd_vs_Mock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/3854109486.py:63: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:18:24,538 [WARNING] Duplicated values found in preranked stats: 42.33% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] KEGG_2021_Human for Co_vs_Mock -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Co_vs_Mock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/3854109486.py:63: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:18:56,664 [WARNING] Duplicated values found in preranked stats: 42.49% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] KEGG_2021_Human for Bt_vs_Cd -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Bt_vs_Cd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/3854109486.py:63: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:19:29,584 [WARNING] Duplicated values found in preranked stats: 42.31% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] KEGG_2021_Human for Bt_vs_Co -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Bt_vs_Co\n",
      "[OK] KEGG_2021_Human for Cd_vs_Co -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/kegg/Cd_vs_Co\n"
     ]
    }
   ],
   "source": [
    "# KEGG via Enrichr (expects GENE SYMBOLS)\n",
    "run_collection(\n",
    "    collection_name=\"KEGG_2021_Human\",   # Enrichr KEGG library\n",
    "    id_type=\"symbol\",                    # <-- use symbols (not Entrez)\n",
    "    out_subdir=\"kegg\"                    # results to analysis/GSEA/kegg/\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc31cf-0e8c-49df-a99b-d6b0c9bbe92f",
   "metadata": {},
   "source": [
    "## Hallmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a25a9264-838f-47dd-884c-18ddd618f950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Bt_vs_Mock: 60,966 ranked symbols\n",
      "[OK] Cd_vs_Mock: 60,966 ranked symbols\n",
      "[OK] Co_vs_Mock: 60,966 ranked symbols\n",
      "[OK] Bt_vs_Cd: 60,966 ranked symbols\n",
      "[OK] Bt_vs_Co: 60,966 ranked symbols\n",
      "[OK] Cd_vs_Co: 60,966 ranked symbols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/3946737025.py:79: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:21:59,420 [WARNING] Duplicated values found in preranked stats: 42.07% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n",
      "/tmp/ipykernel_1853692/3946737025.py:79: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:22:08,696 [WARNING] Duplicated values found in preranked stats: 42.06% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Hallmark GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/hallmark/Bt_vs_Mock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/3946737025.py:79: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:22:24,649 [WARNING] Duplicated values found in preranked stats: 42.11% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Hallmark GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/hallmark/Cd_vs_Mock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/3946737025.py:79: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:22:36,727 [WARNING] Duplicated values found in preranked stats: 42.33% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Hallmark GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/hallmark/Co_vs_Mock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/3946737025.py:79: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:22:52,427 [WARNING] Duplicated values found in preranked stats: 42.49% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Hallmark GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/hallmark/Bt_vs_Cd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1853692/3946737025.py:79: DeprecationWarning: processes is deprecated; use threads\n",
      "  prer = gp.prerank(\n",
      "2025-09-17 16:23:07,683 [WARNING] Duplicated values found in preranked stats: 42.31% of genes\n",
      "The order of those genes will be arbitrary, which may produce unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Hallmark GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/hallmark/Bt_vs_Co\n",
      "[OK] Hallmark GSEA saved -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/hallmark/Cd_vs_Co\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'FDR_q'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/gsea/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FDR_q'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 100\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c, df \u001b[38;5;129;01min\u001b[39;00m all_res\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m--> 100\u001b[0m         keep\u001b[38;5;241m.\u001b[39mupdate(df\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFDR_q\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTerm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[WARN] No Hallmark terms at FDR<0.05. Consider raising permutations or threshold.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/gsea/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniforge3/envs/gsea/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FDR_q'"
     ]
    }
   ],
   "source": [
    "# --- HALLMARK GSEA (symbols) + NES heatmap ---\n",
    "from pathlib import Path\n",
    "import re, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, leaves_list\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Paths\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "ANALYSIS_DIR = BASE / \"analysis\"\n",
    "DE_DIR   = ANALYSIS_DIR / \"DE\"\n",
    "GSEA_DIR = ANALYSIS_DIR / \"GSEA\" / \"hallmark\"\n",
    "FIG_DIR  = ANALYSIS_DIR / \"figures\"\n",
    "GSEA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Your contrasts from the Python-only DE\n",
    "contrasts = [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\",\"Bt_vs_Cd\",\"Bt_vs_Co\",\"Cd_vs_Co\"]\n",
    "\n",
    "def strip_ver(x: str) -> str:\n",
    "    return re.sub(r\"\\.\\d+$\", \"\", x)\n",
    "\n",
    "# ---------- Build Ensembl(core) -> SYMBOL map from adata_ens.var ----------\n",
    "# Prefer 'gene_symbol', else 'gene_symbols'\n",
    "sym_col = \"gene_symbol\" if \"gene_symbol\" in adata_ens.var.columns else (\n",
    "          \"gene_symbols\" if \"gene_symbols\" in adata_ens.var.columns else None)\n",
    "if sym_col is None:\n",
    "    raise ValueError(\"No 'gene_symbol' or 'gene_symbols' in adata_ens.var\")\n",
    "\n",
    "# Use precomputed core IDs if present, else strip version from var_names\n",
    "if \"ensembl_core\" in adata_ens.var.columns:\n",
    "    core_ids = adata_ens.var[\"ensembl_core\"].astype(str).values\n",
    "else:\n",
    "    core_ids = pd.Index(adata_ens.var_names.astype(str)).map(strip_ver).values\n",
    "\n",
    "ens2sym = pd.Series(adata_ens.var[sym_col].astype(str).values, index=core_ids)\n",
    "\n",
    "# ---------- Build preranked lists (t-stat) per contrast ----------\n",
    "ranked = {}  # contrast -> DataFrame with columns ['symbol','score']\n",
    "for c in contrasts:\n",
    "    f = DE_DIR / f\"python_voomlite_{c}.csv\"\n",
    "    if not f.exists():\n",
    "        print(f\"[WARN] missing DE file: {f} — skipping\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(f)\n",
    "    df[\"gene\"] = df[\"gene\"].astype(str)\n",
    "    df[\"gene_core\"] = df[\"gene\"].map(strip_ver)\n",
    "    df[\"symbol\"] = df[\"gene_core\"].map(ens2sym)\n",
    "\n",
    "    # rank by t-stat (preferred), else signed -log10(p)\n",
    "    if \"t\" in df.columns and np.isfinite(df[\"t\"]).any():\n",
    "        score = pd.to_numeric(df[\"t\"], errors=\"coerce\")\n",
    "    else:\n",
    "        score = np.sign(pd.to_numeric(df[\"logFC\"], errors=\"coerce\")) * (\n",
    "            -np.log10(np.clip(pd.to_numeric(df[\"pval\"], errors=\"coerce\"), 1e-300, 1.0))\n",
    "        )\n",
    "\n",
    "    rnk = pd.DataFrame({\"symbol\": df[\"symbol\"], \"score\": score})\n",
    "    # drop NA/blank, resolve duplicate symbols by max |score|\n",
    "    rnk = rnk.dropna()\n",
    "    rnk = rnk[rnk[\"symbol\"].astype(str).str.len() > 0]\n",
    "    rnk = rnk.sort_values(\"score\", key=lambda x: x.abs(), ascending=False).drop_duplicates(\"symbol\")\n",
    "    rnk = rnk.sort_values(\"score\", ascending=False)\n",
    "    ranked[c] = rnk\n",
    "    print(f\"[OK] {c}: {len(rnk):,} ranked symbols\")\n",
    "\n",
    "# ---------- Run gseapy prerank on Hallmark ----------\n",
    "import gseapy as gp\n",
    "\n",
    "all_res = {}\n",
    "for c, rnk in ranked.items():\n",
    "    outdir = GSEA_DIR / c\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Option A (default): Enrichr Hallmark collection (symbol-based)\n",
    "    gene_sets = \"MSigDB_Hallmark_2020\"\n",
    "    # Option B (licensed MSigDB GMT): e.g., \"/path/to/h.all.v2023.2.Hs.symbols.gmt\"\n",
    "    # gene_sets = \"/path/to/h.all.*.symbols.gmt\"\n",
    "\n",
    "    prer = gp.prerank(\n",
    "        rnk=rnk,                    # pass DataFrame directly\n",
    "        gene_sets=gene_sets,\n",
    "        processes=4,\n",
    "        permutation_num=1000,\n",
    "        min_size=10, max_size=1000,\n",
    "        seed=42,\n",
    "        outdir=str(outdir),\n",
    "        format=\"png\"               # enrichment plots saved per term\n",
    "    )\n",
    "    res2d = prer.res2d.copy()\n",
    "    res2d.rename(columns={\"fdr\":\"FDR_q\"}, inplace=True)\n",
    "    res2d.to_csv(outdir / \"gsea_hallmark_results.csv\", index=False)\n",
    "    all_res[c] = res2d\n",
    "    print(f\"[OK] Hallmark GSEA saved -> {outdir}\")\n",
    "\n",
    "# ---------- NES matrix & clustered heatmap (terms x contrasts) ----------\n",
    "# keep terms significant in ≥1 contrast (FDR_q < 0.05)\n",
    "keep = set()\n",
    "for c, df in all_res.items():\n",
    "    if not df.empty:\n",
    "        keep.update(df.loc[df[\"FDR_q\"] < 0.05, \"Term\"].tolist())\n",
    "\n",
    "if not keep:\n",
    "    print(\"[WARN] No Hallmark terms at FDR<0.05. Consider raising permutations or threshold.\")\n",
    "else:\n",
    "    terms = sorted(keep)\n",
    "    NES = pd.DataFrame(index=terms, columns=contrasts, dtype=float)\n",
    "    FDR = pd.DataFrame(index=terms, columns=contrasts, dtype=float)\n",
    "    for c in contrasts:\n",
    "        if c in all_res and not all_res[c].empty:\n",
    "            df = all_res[c].set_index(\"Term\")\n",
    "            NES.loc[terms, c] = df.reindex(terms)[\"NES\"].values\n",
    "            FDR.loc[terms, c] = df.reindex(terms)[\"FDR_q\"].values\n",
    "\n",
    "    NES = NES.astype(float).fillna(0.0).clip(-3.5, 3.5)\n",
    "\n",
    "    # cluster rows & columns by correlation distance\n",
    "    def corr_linkage(mat, axis=0, method=\"average\"):\n",
    "        X = mat if axis == 0 else mat.T\n",
    "        C = np.corrcoef(X)\n",
    "        D = np.clip(1 - C, 0, 2)\n",
    "        return linkage(squareform(D, checks=False), method=method)\n",
    "\n",
    "    row_link = corr_linkage(NES.values, axis=0, method=\"average\")\n",
    "    col_link = corr_linkage(NES.values, axis=1, method=\"average\")\n",
    "    row_ord  = leaves_list(row_link)\n",
    "    col_ord  = leaves_list(col_link)\n",
    "\n",
    "    NES_ord = NES.values[row_ord][:, col_ord]\n",
    "    row_lbl = [NES.index[i] for i in row_ord]\n",
    "    col_lbl = [NES.columns[i] for i in col_ord]\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(max(8, 0.45*len(col_lbl)+3), max(8, 0.22*len(row_lbl)+3)))\n",
    "    ax_top = plt.axes([0.28, 0.90, 0.62, 0.08]); dendrogram(col_link, ax=ax_top, no_labels=True); ax_top.axis(\"off\")\n",
    "    ax_left = plt.axes([0.07, 0.20, 0.20, 0.70]); dendrogram(row_link, ax=ax_left, orientation=\"right\", no_labels=True); ax_left.axis(\"off\")\n",
    "    ax = plt.axes([0.28, 0.20, 0.62, 0.70])\n",
    "    im = ax.imshow(NES_ord, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    ax.set_xticks(range(len(col_lbl))); ax.set_xticklabels(col_lbl, rotation=45, ha=\"right\", fontsize=9)\n",
    "    ax.set_yticks(range(len(row_lbl))); ax.set_yticklabels(row_lbl, fontsize=9)\n",
    "    ax.set_title(\"HALLMARK GSEA (NES, FDR<0.05)\")\n",
    "    cax = plt.axes([0.91, 0.20, 0.02, 0.70]); cb = plt.colorbar(im, cax=cax); cb.set_label(\"NES\")\n",
    "\n",
    "    out_png = FIG_DIR / \"hallmark_gsea_NES_heatmap.png\"\n",
    "    plt.savefig(out_png, dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "    NES.to_csv(GSEA_DIR / \"hallmark_NES_matrix.csv\")\n",
    "    FDR.to_csv(GSEA_DIR / \"hallmark_FDR_matrix.csv\")\n",
    "    print(f\"[OK] NES heatmap -> {out_png}\")\n",
    "    print(f\"[OK] NES/FDR matrices -> {GSEA_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35d2fe-f780-48f0-b115-9d3df3a965f0",
   "metadata": {},
   "source": [
    "## Meta anaylsis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84d10bcb-c13e-43ea-b077-64c865257b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bt_vs_Mock: no significant pathways at FDR<0.9.\n",
      "\n",
      "Cd_vs_Mock: no significant pathways at FDR<0.9.\n",
      "\n",
      "Co_vs_Mock: no significant pathways at FDR<0.9.\n",
      "\n",
      "[OK] Wrote:\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/GSEA_top_terms_by_contrast.csv\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/GSEA_recurring_terms.csv\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/GSEA_overview_long.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ------------------ Config ------------------\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "ANALYSIS_DIR = BASE / \"analysis\"\n",
    "GSEA_BASE = ANALYSIS_DIR / \"GSEA\"\n",
    "OUT_DIR = GSEA_BASE / \"summary\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Your contrasts (adapt if you want to focus on vs-Mock only)\n",
    "contrasts = [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\",\"Bt_vs_Cd\",\"Bt_vs_Co\",\"Cd_vs_Co\"]\n",
    "collections = {\n",
    "    \"reactome\": {\n",
    "        \"dir\": GSEA_BASE / \"reactome\",\n",
    "        \"filename\": \"gsea_reactome_results.csv\"\n",
    "    },\n",
    "    \"kegg\": {\n",
    "        \"dir\": GSEA_BASE / \"kegg\",\n",
    "        \"filename\": \"gsea_kegg_results.csv\"\n",
    "    },\n",
    "    \"hallmark\": {\n",
    "        \"dir\": GSEA_BASE / \"hallmark\",\n",
    "        \"filename\": \"gsea_hallmark_results.csv\"\n",
    "    },\n",
    "}\n",
    "\n",
    "FDR_THRESH = 0.9\n",
    "TOP_N = 10   # top N per contrast x collection for the overview\n",
    "\n",
    "# ------------------ Helpers ------------------\n",
    "def _std_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Robustly standardize GSEA result columns across gseapy versions/collections.\"\"\"\n",
    "    # Lowercase for matching\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "    # Find likely columns\n",
    "    term_col = lower.get(\"term\", None)\n",
    "    if term_col is None:\n",
    "        # sometimes 'name' or 'pathway' occurs\n",
    "        for cand in [\"name\", \"pathway\", \"gs\"]:\n",
    "            if cand in lower:\n",
    "                term_col = lower[cand]; break\n",
    "    nes_col = lower.get(\"nes\", None)\n",
    "    if nes_col is None:\n",
    "        for cand in [\"normalized enrichment score\", \"normalized_enrichment_score\"]:\n",
    "            if cand in lower:\n",
    "                nes_col = lower[cand]; break\n",
    "    fdr_col = lower.get(\"fdr_q\", None)\n",
    "    if fdr_col is None:\n",
    "        # gseapy often uses 'fdr'\n",
    "        fdr_col = lower.get(\"fdr\", None)\n",
    "    p_col = lower.get(\"pval\", None)\n",
    "    if p_col is None:\n",
    "        for cand in [\"p-value\", \"pvalue\", \"p\", \"nominal p-value\", \"pval_nom\"]:\n",
    "            if cand in lower:\n",
    "                p_col = lower[cand]; break\n",
    "    lead_col = None\n",
    "    # various names: 'lead_genes', 'leading_edge', 'ledge_genes', 'genes'\n",
    "    for cand in [\"lead_genes\", \"leading_edge\", \"ledge_genes\", \"genes\", \"hits\"]:\n",
    "        if cand in lower:\n",
    "            lead_col = lower[cand]; break\n",
    "\n",
    "    out = pd.DataFrame()\n",
    "    if term_col is not None: out[\"Term\"] = df[term_col].astype(str)\n",
    "    if nes_col is not None:  out[\"NES\"] = pd.to_numeric(df[nes_col], errors=\"coerce\")\n",
    "    if fdr_col is not None:  out[\"FDR_q\"] = pd.to_numeric(df[fdr_col], errors=\"coerce\")\n",
    "    if p_col is not None:    out[\"pval\"] = pd.to_numeric(df[p_col], errors=\"coerce\")\n",
    "    if lead_col is not None: out[\"lead_genes\"] = df[lead_col].astype(str)\n",
    "    # Keep anything else you want by merging later if needed\n",
    "    return out\n",
    "\n",
    "def _direction_label(nes):\n",
    "    return \"Up (first group)\" if nes > 0 else \"Down (second group)\"\n",
    "\n",
    "def _short_contrast_side(contrast: str):\n",
    "    \"\"\"Return 'first' vs 'second' names (e.g., 'Bt','Mock').\"\"\"\n",
    "    if \"_vs_\" in contrast:\n",
    "        a, b = contrast.split(\"_vs_\", 1)\n",
    "    else:\n",
    "        parts = contrast.split(\"vs\")\n",
    "        a, b = parts[0], parts[1]\n",
    "    return a, b\n",
    "\n",
    "# ------------------ Load & unify ------------------\n",
    "all_rows = []\n",
    "missing = []\n",
    "\n",
    "for coll, info in collections.items():\n",
    "    for c in contrasts:\n",
    "        f = info[\"dir\"] / c / info[\"filename\"]\n",
    "        if not f.exists():\n",
    "            missing.append(str(f))\n",
    "            continue\n",
    "        raw = pd.read_csv(f)\n",
    "        df = _std_cols(raw)\n",
    "        if df.empty or \"Term\" not in df.columns or \"NES\" not in df.columns:\n",
    "            continue\n",
    "        df[\"collection\"] = coll\n",
    "        df[\"contrast\"] = c\n",
    "        a, b = _short_contrast_side(c)\n",
    "        df[\"group_first\"] = a\n",
    "        df[\"group_second\"] = b\n",
    "        # fallback if FDR_q missing: try to derive from pval (not ideal)\n",
    "        if \"FDR_q\" not in df.columns or df[\"FDR_q\"].isna().all():\n",
    "            if \"pval\" in df.columns:\n",
    "                from statsmodels.stats.multitest import multipletests\n",
    "                df[\"FDR_q\"] = multipletests(df[\"pval\"].fillna(1.0), method=\"fdr_bh\")[1]\n",
    "            else:\n",
    "                df[\"FDR_q\"] = np.nan\n",
    "        all_rows.append(df)\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"No GSEA result files found. Missing: \\n\" + \"\\n\".join(missing[:10]))\n",
    "\n",
    "gsea_all = pd.concat(all_rows, ignore_index=True)\n",
    "# Clean terms (optional: shorten long Reactome names)\n",
    "gsea_all[\"Term_clean\"] = (gsea_all[\"Term\"]\n",
    "                          .str.replace(\"^REACTOME_\", \"\", regex=True)\n",
    "                          .str.replace(\"^HALLMARK_\", \"\", regex=True)\n",
    "                          .str.replace(\"_\", \" \"))\n",
    "\n",
    "# Significance filter\n",
    "sig = gsea_all[(gsea_all[\"FDR_q\"] < FDR_THRESH) & gsea_all[\"NES\"].notna()].copy()\n",
    "sig[\"Direction\"] = np.where(sig[\"NES\"] > 0, \"Up (first group)\", \"Down (second group)\")\n",
    "\n",
    "# ------------------ Top N per contrast x collection ------------------\n",
    "def top_by_contrast(df_sig, top_n=TOP_N):\n",
    "    out = []\n",
    "    for (c, coll), sub in df_sig.groupby([\"contrast\",\"collection\"]):\n",
    "        if sub.empty: continue\n",
    "        # sort by FDR, then by |NES| desc, then by pval\n",
    "        sub = sub.sort_values([\"FDR_q\", \"NES\", \"pval\"], ascending=[True, False, True])\n",
    "        out.append(sub.head(top_n))\n",
    "    return pd.concat(out, ignore_index=True) if out else pd.DataFrame()\n",
    "\n",
    "topN = top_by_contrast(sig, TOP_N)\n",
    "topN_cols = [\"collection\",\"contrast\",\"group_first\",\"group_second\",\"Term_clean\",\"NES\",\"FDR_q\",\"Direction\",\"lead_genes\"]\n",
    "topN = topN[[c for c in topN_cols if c in topN.columns]]\n",
    "topN.rename(columns={\"Term_clean\":\"Term\"}, inplace=True)\n",
    "topN.to_csv(OUT_DIR / \"GSEA_top_terms_by_contrast.csv\", index=False)\n",
    "\n",
    "# ------------------ Recurring pathways across contrasts ------------------\n",
    "recurring = (sig.groupby([\"collection\",\"Term\"])\n",
    "                .agg(n_sig=(\"NES\",\"size\"),\n",
    "                     mean_NES=(\"NES\",\"mean\"),\n",
    "                     min_FDR=(\"FDR_q\",\"min\"))\n",
    "                .reset_index()\n",
    "                .sort_values([\"n_sig\",\"min_FDR\"], ascending=[False, True]))\n",
    "recurring.to_csv(OUT_DIR / \"GSEA_recurring_terms.csv\", index=False)\n",
    "\n",
    "# ------------------ Tidy long (all significant) ------------------\n",
    "sig_out = sig.copy()\n",
    "sig_out = sig_out[[\"collection\",\"contrast\",\"group_first\",\"group_second\",\"Term_clean\",\"NES\",\"FDR_q\",\"Direction\",\"lead_genes\"]]\n",
    "sig_out.rename(columns={\"Term_clean\":\"Term\"}, inplace=True)\n",
    "sig_out.to_csv(OUT_DIR / \"GSEA_overview_long.csv\", index=False)\n",
    "\n",
    "# ------------------ Quick console summary (vs Mock only) ------------------\n",
    "def brief_summary(df, contrast):\n",
    "    sub = df[(df[\"contrast\"]==contrast)]\n",
    "    if sub.empty:\n",
    "        print(f\"\\n{contrast}: no significant pathways at FDR<{FDR_THRESH}.\")\n",
    "        return\n",
    "    a, b = _short_contrast_side(contrast)\n",
    "    up = (sub[sub[\"NES\"]>0]\n",
    "          .sort_values([\"FDR_q\",\"NES\"], ascending=[True,False])\n",
    "          .groupby(\"collection\")\n",
    "          .head(5))\n",
    "    down = (sub[sub[\"NES\"]<0]\n",
    "            .sort_values([\"FDR_q\",\"NES\"], ascending=[True,True])  # most negative NES first\n",
    "            .groupby(\"collection\")\n",
    "            .head(5))\n",
    "    print(f\"\\n=== {contrast} (Up = enriched in {a}, Down = enriched in {b}) ===\")\n",
    "    if not up.empty:\n",
    "        print(\"\\nTop UP (by collection):\")\n",
    "        for _, r in up.iterrows():\n",
    "            print(f\"  [{r['collection']}] {r['Term']}  NES={r['NES']:.2f}  FDR={r['FDR_q']:.3g}\")\n",
    "    if not down.empty:\n",
    "        print(\"\\nTop DOWN (by collection):\")\n",
    "        for _, r in down.iterrows():\n",
    "            print(f\"  [{r['collection']}] {r['Term']}  NES={r['NES']:.2f}  FDR={r['FDR_q']:.3g}\")\n",
    "\n",
    "for c in [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\"]:\n",
    "    brief_summary(sig_out, c)\n",
    "\n",
    "print(\"\\n[OK] Wrote:\")\n",
    "print(\" -\", OUT_DIR / \"GSEA_top_terms_by_contrast.csv\")\n",
    "print(\" -\", OUT_DIR / \"GSEA_recurring_terms.csv\")\n",
    "print(\" -\", OUT_DIR / \"GSEA_overview_long.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e915df67-6dc6-4289-b887-038c6bcb991a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Bt_vs_Mock (Up=Bt, Down=Mock) ===\n",
      " Top UP:\n",
      "  [reactome] prerank  NES=2.31  FDR=0\n",
      "  [reactome] prerank  NES=2.29  FDR=0\n",
      "  [reactome] prerank  NES=2.28  FDR=0\n",
      "  [kegg] prerank  NES=2.21  FDR=0\n",
      "  [kegg] prerank  NES=2.12  FDR=0\n",
      "  [kegg] prerank  NES=2.05  FDR=0\n",
      "  [hallmark] prerank  NES=1.87  FDR=0.002\n",
      "  [hallmark] prerank  NES=1.65  FDR=0.011\n",
      "  [hallmark] prerank  NES=1.51  FDR=0.0266\n",
      "\n",
      "=== Cd_vs_Mock (Up=Cd, Down=Mock) ===\n",
      " Top UP:\n",
      "  [hallmark] prerank  NES=2.19  FDR=0\n",
      "  [kegg] prerank  NES=2.08  FDR=0\n",
      "  [kegg] prerank  NES=2.02  FDR=0\n",
      "  [hallmark] prerank  NES=1.99  FDR=0\n",
      "  [kegg] prerank  NES=1.98  FDR=0\n",
      "  [hallmark] prerank  NES=1.93  FDR=0\n",
      "  [reactome] prerank  NES=2.05  FDR=0.000548\n",
      "  [reactome] prerank  NES=2.06  FDR=0.000822\n",
      "  [reactome] prerank  NES=2.04  FDR=0.000822\n",
      " Top DOWN:\n",
      "  [kegg] prerank  NES=-1.78  FDR=0.0736\n",
      "\n",
      "=== Co_vs_Mock (Up=Co, Down=Mock) ===\n",
      " Top UP:\n",
      "  [kegg] prerank  NES=1.74  FDR=0.0514\n",
      "  [hallmark] prerank  NES=1.45  FDR=0.0669\n",
      "  [kegg] prerank  NES=1.67  FDR=0.0759\n",
      "  [hallmark] prerank  NES=1.46  FDR=0.0882\n",
      "  [kegg] prerank  NES=1.61  FDR=0.089\n",
      " Top DOWN:\n",
      "  [kegg] prerank  NES=-1.93  FDR=0.0105\n",
      "  [kegg] prerank  NES=-1.67  FDR=0.0837\n",
      "  [hallmark] prerank  NES=-1.57  FDR=0.0819\n",
      "  [hallmark] prerank  NES=-1.53  FDR=0.0514\n",
      "  [hallmark] prerank  NES=-1.43  FDR=0.0805\n",
      "\n",
      "[OK] Wrote:\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/GSEA_top_terms_by_contrast.csv\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/GSEA_recurring_terms.csv\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/GSEA_overview_long.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional  # <-- fix for older Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ------------------ Config ------------------\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "ANALYSIS_DIR = BASE / \"analysis\"\n",
    "GSEA_BASE = ANALYSIS_DIR / \"GSEA\"\n",
    "OUT_DIR = GSEA_BASE / \"summary\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "contrasts = [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\",\"Bt_vs_Cd\",\"Bt_vs_Co\",\"Cd_vs_Co\"]\n",
    "collections = {\n",
    "    \"reactome\": {\"dir\": GSEA_BASE / \"reactome\", \"fname\": \"gsea_reactome_results.csv\"},\n",
    "    \"kegg\":     {\"dir\": GSEA_BASE / \"kegg\",     \"fname\": \"gsea_kegg_results.csv\"},\n",
    "    \"hallmark\": {\"dir\": GSEA_BASE / \"hallmark\", \"fname\": \"gsea_hallmark_results.csv\"},\n",
    "}\n",
    "ALT_REPORT = \"gseapy.gene_set.prerank.report.csv\"  # fallback\n",
    "\n",
    "FDR_THRESH = 0.09\n",
    "TOP_N      = 10\n",
    "\n",
    "# ------------------ Robust standardization ------------------\n",
    "def read_gsea_csv(path: Path) -> pd.DataFrame:\n",
    "    # auto-detect delimiter (tab/comma)\n",
    "    return pd.read_csv(path, sep=None, engine=\"python\")\n",
    "\n",
    "def _pick_col(cols_lower, patterns):\n",
    "    for c_low, c_orig in cols_lower.items():\n",
    "        for pat in patterns:\n",
    "            if re.search(pat, c_low, flags=re.I):\n",
    "                return c_orig\n",
    "    return None\n",
    "\n",
    "def _std_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cl = {c.lower(): c for c in df.columns}\n",
    "    term = _pick_col(cl, [r\"^term$\", r\"^name$\", r\"^pathway$\", r\"^gs$\", r\"description\"])\n",
    "    nes  = _pick_col(cl, [r\"^nes$\", r\"normalized[ _-]?enrichment\"])\n",
    "    fdr  = _pick_col(cl, [r\"^fdr(_?q)?$\", r\"^fdr[ _-]?q[ _-]?val(ue)?$\", r\"^q[ _-]?val\"])\n",
    "    pvl  = _pick_col(cl, [r\"^pval$\", r\"^p[-_ ]?value$\", r\"^p$\", r\"^nom.*p.*val\"])\n",
    "    led  = _pick_col(cl, [r\"^lead.*gene\", r\"leading.*edge\", r\"ledge.*gene\", r\"^genes$\", r\"^hits$\"])\n",
    "\n",
    "    out = pd.DataFrame()\n",
    "    if term is not None: out[\"Term\"] = df[term].astype(str)\n",
    "    if nes  is not None: out[\"NES\"]  = pd.to_numeric(df[nes], errors=\"coerce\")\n",
    "    if fdr  is not None: out[\"FDR_q\"]= pd.to_numeric(df[fdr], errors=\"coerce\")\n",
    "    if pvl  is not None: out[\"pval\"] = pd.to_numeric(df[pvl], errors=\"coerce\")\n",
    "    if led  is not None: out[\"lead_genes\"] = df[led].astype(str)\n",
    "    return out\n",
    "\n",
    "def first_existing(*paths: Path) -> Optional[Path]:  # <-- fixed hint\n",
    "    for p in paths:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "# ------------------ Load all collections ------------------\n",
    "all_rows, missing = [], []\n",
    "\n",
    "for coll, info in collections.items():\n",
    "    for c in contrasts:\n",
    "        base = info[\"dir\"] / c\n",
    "        main = base / info[\"fname\"]\n",
    "        alt  = base / ALT_REPORT\n",
    "        usef = first_existing(main, alt)\n",
    "        if usef is None:\n",
    "            missing.append(str(main))\n",
    "            continue\n",
    "        raw = read_gsea_csv(usef)\n",
    "        df  = _std_cols(raw)\n",
    "        if df.empty or \"Term\" not in df.columns or \"NES\" not in df.columns:\n",
    "            continue\n",
    "        # ensure FDR_q\n",
    "        if \"FDR_q\" not in df.columns or df[\"FDR_q\"].isna().all():\n",
    "            if \"pval\" in df.columns:\n",
    "                df[\"FDR_q\"] = multipletests(df[\"pval\"].fillna(1.0), method=\"fdr_bh\")[1]\n",
    "            else:\n",
    "                df[\"FDR_q\"] = np.nan\n",
    "\n",
    "        df[\"collection\"]   = coll\n",
    "        df[\"contrast\"]     = c\n",
    "        a, b = c.split(\"_vs_\", 1) if \"_vs_\" in c else c.split(\"vs\", 1)\n",
    "        df[\"group_first\"]  = a\n",
    "        df[\"group_second\"] = b\n",
    "        all_rows.append(df)\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"No GSEA result files found.\\nExamples missing:\\n\" + \"\\n\".join(missing[:10]))\n",
    "\n",
    "gsea = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "# Normalize term names a bit\n",
    "gsea[\"Term\"] = (gsea[\"Term\"]\n",
    "                .str.replace(r\"^REACTOME_\", \"\", regex=True)\n",
    "                .str.replace(r\"^HALLMARK_\", \"\", regex=True)\n",
    "                .str.replace(\"_\", \" \"))\n",
    "\n",
    "# ------------------ Filter + simple summaries ------------------\n",
    "sig = gsea[(gsea[\"NES\"].notna()) & (gsea[\"FDR_q\"].notna()) & (gsea[\"FDR_q\"] < FDR_THRESH)].copy()\n",
    "sig[\"Direction\"] = np.where(sig[\"NES\"] > 0, \"Up (first group)\", \"Down (second group)\")\n",
    "\n",
    "def top_by_contrast(df_sig, top_n=TOP_N):\n",
    "    out = []\n",
    "    for (c, coll), sub in df_sig.groupby([\"contrast\",\"collection\"]):\n",
    "        sub = sub.sort_values([\"FDR_q\", \"NES\"], ascending=[True, False])\n",
    "        out.append(sub.head(top_n))\n",
    "    return pd.concat(out, ignore_index=True) if out else pd.DataFrame()\n",
    "\n",
    "topN = top_by_contrast(sig, TOP_N)\n",
    "topN_cols = [\"collection\",\"contrast\",\"group_first\",\"group_second\",\"Term\",\"NES\",\"FDR_q\",\"Direction\",\"lead_genes\"]\n",
    "topN = topN[[c for c in topN_cols if c in topN.columns]]\n",
    "topN.to_csv(OUT_DIR / \"GSEA_top_terms_by_contrast.csv\", index=False)\n",
    "\n",
    "recurring = (sig.groupby([\"collection\",\"Term\"])\n",
    "               .agg(n_sig=(\"NES\",\"size\"),\n",
    "                    mean_NES=(\"NES\",\"mean\"),\n",
    "                    min_FDR=(\"FDR_q\",\"min\"))\n",
    "               .reset_index()\n",
    "               .sort_values([\"n_sig\",\"min_FDR\"], ascending=[False, True]))\n",
    "recurring.to_csv(OUT_DIR / \"GSEA_recurring_terms.csv\", index=False)\n",
    "\n",
    "sig.to_csv(OUT_DIR / \"GSEA_overview_long.csv\", index=False)\n",
    "\n",
    "# Quick console glance (vs Mock only)\n",
    "for c in [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\"]:\n",
    "    sub = sig[sig[\"contrast\"]==c].sort_values([\"FDR_q\",\"NES\"], ascending=[True,False])\n",
    "    a, b = c.split(\"_vs_\", 1)\n",
    "    if sub.empty:\n",
    "        print(f\"{c}: no pathways at FDR<{FDR_THRESH}.\")\n",
    "    else:\n",
    "        up = sub[sub[\"NES\"]>0].groupby(\"collection\").head(3)\n",
    "        down = sub[sub[\"NES\"]<0].sort_values(\"NES\").groupby(\"collection\").head(3)\n",
    "        print(f\"\\n=== {c} (Up={a}, Down={b}) ===\")\n",
    "        if not up.empty:\n",
    "            print(\" Top UP:\")\n",
    "            for _, r in up.iterrows():\n",
    "                print(f\"  [{r['collection']}] {r['Term']}  NES={r['NES']:.2f}  FDR={r['FDR_q']:.3g}\")\n",
    "        if not down.empty:\n",
    "            print(\" Top DOWN:\")\n",
    "            for _, r in down.iterrows():\n",
    "                print(f\"  [{r['collection']}] {r['Term']}  NES={r['NES']:.2f}  FDR={r['FDR_q']:.3g}\")\n",
    "\n",
    "print(\"\\n[OK] Wrote:\")\n",
    "print(\" -\", OUT_DIR / \"GSEA_top_terms_by_contrast.csv\")\n",
    "print(\" -\", OUT_DIR / \"GSEA_recurring_terms.csv\")\n",
    "print(\" -\", OUT_DIR / \"GSEA_overview_long.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b11e5d3e-99d3-4499-8ae0-8d0fd25b0e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Overlap (UP) -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/drivers_overlap_UP_counts.csv & /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/drivers_overlap_UP_lists.csv\n",
      "[OK] Overlap (DOWN) -> /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/drivers_overlap_DOWN_counts.csv & /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/drivers_overlap_DOWN_lists.csv\n",
      "\n",
      "[OK] Wrote:\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/GSEA_top_terms_with_genes.csv\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/GSEA_top_terms_membership.csv\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/driver_bags/ (UP/DOWN txt lists)\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/drivers_overlap_UP_counts.csv and _lists.(csv|json)\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/drivers_overlap_DOWN_counts.csv and _lists.(csv|json)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import pandas as pd, numpy as np, re, json\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ------------------ Config ------------------\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "ANALYSIS_DIR = BASE / \"analysis\"\n",
    "GSEA_BASE = ANALYSIS_DIR / \"GSEA\"\n",
    "OUT_DIR = GSEA_BASE / \"summary\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "contrasts = [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\",\"Bt_vs_Cd\",\"Bt_vs_Co\",\"Cd_vs_Co\"]\n",
    "collections = {\n",
    "    \"reactome\": {\"dir\": GSEA_BASE / \"reactome\", \"fname\": \"gsea_reactome_results.csv\"},\n",
    "    \"kegg\":     {\"dir\": GSEA_BASE / \"kegg\",     \"fname\": \"gsea_kegg_results.csv\"},\n",
    "    \"hallmark\": {\"dir\": GSEA_BASE / \"hallmark\", \"fname\": \"gsea_hallmark_results.csv\"},\n",
    "}\n",
    "ALT_REPORT = \"gseapy.gene_set.prerank.report.csv\"  # fallback in each contrast folder\n",
    "\n",
    "FDR_THRESH = 0.05\n",
    "TOP_N = 10  # top per contrast x collection for overview\n",
    "\n",
    "# ------------------ Helpers ------------------\n",
    "def read_gsea_csv(path: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(path, sep=None, engine=\"python\")\n",
    "\n",
    "def _pick_col(cols_lower, patterns):\n",
    "    # prefer patterns (e.g., 'term') over whatever comes first in file (e.g., 'name')\n",
    "    for pat in patterns:\n",
    "        for c_low, c_orig in cols_lower.items():\n",
    "            if re.search(pat, c_low, flags=re.I):\n",
    "                return c_orig\n",
    "    return None\n",
    "\n",
    "def standardize_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cl = {c.lower(): c for c in df.columns}\n",
    "    term = _pick_col(cl, [r\"^term$\", r\"description\", r\"^pathway$\", r\"^gs$\", r\"^name$\"])  # 'term' first!\n",
    "    nes  = _pick_col(cl, [r\"^nes$\", r\"normalized[ _-]?enrichment\"])\n",
    "    fdr  = _pick_col(cl, [r\"^fdr(_?q)?$\", r\"fdr[ _-]?q[ _-]?val(ue)?\", r\"^q[ _-]?val\"])\n",
    "    pvl  = _pick_col(cl, [r\"^pval$\", r\"^p[-_ ]?value$\", r\"^p$\", r\"^nom.*p.*val\"])\n",
    "    # leading edge sometimes appears under different headers\n",
    "    led  = _pick_col(cl, [r\"^lead.*gene\", r\"leading.*edge\", r\"^genes$\", r\"^hits$\"])\n",
    "\n",
    "    out = pd.DataFrame()\n",
    "    if term is not None: out[\"Term\"] = df[term].astype(str)\n",
    "    if nes  is not None:  out[\"NES\"]  = pd.to_numeric(df[nes], errors=\"coerce\")\n",
    "    if fdr  is not None:  out[\"FDR_q\"]= pd.to_numeric(df[fdr], errors=\"coerce\")\n",
    "    if pvl  is not None:  out[\"pval\"] = pd.to_numeric(df[pvl], errors=\"coerce\")\n",
    "    if led  is not None:  out[\"lead_genes\"] = df[led].astype(str)\n",
    "    return out\n",
    "\n",
    "def first_existing(*paths: Path) -> Optional[Path]:\n",
    "    for p in paths:\n",
    "        if p.exists(): return p\n",
    "    return None\n",
    "\n",
    "# Parse GMT membership (term -> list of genes)\n",
    "def load_gmt_membership(gmt_path: Path) -> dict[str, list[str]]:\n",
    "    mem = {}\n",
    "    if not gmt_path.exists(): return mem\n",
    "    with gmt_path.open() as fh:\n",
    "        for line in fh:\n",
    "            parts = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            if len(parts) >= 3:\n",
    "                term = parts[0]\n",
    "                genes = [g for g in parts[2:] if g]\n",
    "                mem[term] = genes\n",
    "    return mem\n",
    "\n",
    "# Split a \"lead_genes\" cell into a list of gene symbols\n",
    "_SPLIT = re.compile(r\"[;,/\\s]+\")\n",
    "def parse_leading_edge_cell(x: str):\n",
    "    if not isinstance(x, str) or not x.strip(): return []\n",
    "    toks = [t for t in _SPLIT.split(x) if t]\n",
    "    # strip obvious non-gene tokens (e.g., 'tags=', 'list=' strings)\n",
    "    toks = [t for t in toks if re.match(r\"^[A-Za-z0-9_.\\-]+$\", t)]\n",
    "    return toks\n",
    "\n",
    "def groups_of(contrast: str):\n",
    "    a, b = contrast.split(\"_vs_\", 1) if \"_vs_\" in contrast else contrast.split(\"vs\", 1)\n",
    "    return a, b\n",
    "\n",
    "# ------------------ Load all results + attach membership ------------------\n",
    "rows = []\n",
    "memberships = {}  # (collection, contrast) -> dict(term -> members)\n",
    "\n",
    "for coll, info in collections.items():\n",
    "    for c in contrasts:\n",
    "        base = info[\"dir\"] / c\n",
    "        usef = first_existing(base / info[\"fname\"], base / ALT_REPORT)\n",
    "        if usef is None:\n",
    "            continue\n",
    "        raw = read_gsea_csv(usef)\n",
    "        df  = standardize_cols(raw)\n",
    "        if df.empty or \"Term\" not in df.columns or \"NES\" not in df.columns:\n",
    "            continue\n",
    "\n",
    "        # ensure FDR_q\n",
    "        if \"FDR_q\" not in df.columns or df[\"FDR_q\"].isna().all():\n",
    "            if \"pval\" in df.columns:\n",
    "                df[\"FDR_q\"] = multipletests(df[\"pval\"].fillna(1.0), method=\"fdr_bh\")[1]\n",
    "            else:\n",
    "                df[\"FDR_q\"] = np.nan\n",
    "\n",
    "        # tidy names a little for display\n",
    "        df[\"Term_display\"] = (df[\"Term\"]\n",
    "            .str.replace(r\"^REACTOME_\", \"\", regex=True)\n",
    "            .str.replace(r\"^HALLMARK_\", \"\", regex=True)\n",
    "            .str.replace(\"_\", \" \"))\n",
    "\n",
    "        df[\"collection\"] = coll\n",
    "        df[\"contrast\"]   = c\n",
    "        a, b = groups_of(c)\n",
    "        df[\"group_first\"] = a\n",
    "        df[\"group_second\"]= b\n",
    "\n",
    "        # attach full membership from the local GMT (if present)\n",
    "        gmt = base / \"gene_sets.gmt\"\n",
    "        mem = load_gmt_membership(gmt)\n",
    "        memberships[(coll, c)] = mem\n",
    "\n",
    "        # try to normalize membership term keys to match Term_display if needed\n",
    "        # Build a fast lookup by a relaxed key\n",
    "        def keyify(s: str) -> str:\n",
    "            return re.sub(r\"[\\s_]+\", \" \", s.strip()).lower()\n",
    "        mem_by_key = {keyify(k): v for k, v in mem.items()}\n",
    "\n",
    "        df[\"members\"] = df[\"Term_display\"].map(lambda t: mem_by_key.get(keyify(t), []))\n",
    "        df[\"set_size\"] = df[\"members\"].map(len)\n",
    "\n",
    "        rows.append(df)\n",
    "\n",
    "if not rows:\n",
    "    raise RuntimeError(\"No GSEA result files parsed. Check file names or folders.\")\n",
    "\n",
    "gsea = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "# ------------------ Filter, top tables with names + genes ------------------\n",
    "sig = gsea[(gsea[\"NES\"].notna()) & (gsea[\"FDR_q\"].notna()) & (gsea[\"FDR_q\"] < FDR_THRESH)].copy()\n",
    "sig[\"Direction\"] = np.where(sig[\"NES\"] > 0, \"Up (first group)\", \"Down (second group)\")\n",
    "\n",
    "# if lead_genes missing, leave as empty list\n",
    "sig[\"lead_genes_list\"] = sig.get(\"lead_genes\", pd.Series([\"\"]*len(sig))).apply(parse_leading_edge_cell)\n",
    "sig[\"lead_n\"] = sig[\"lead_genes_list\"].map(len)\n",
    "sig[\"lead_preview\"] = sig[\"lead_genes_list\"].apply(lambda xs: \", \".join(xs[:15]) + (\" ...\" if len(xs)>15 else \"\"))\n",
    "\n",
    "# Top N per contrast x collection (with Term names + lead genes)\n",
    "def top_by_contrast(df_sig, top_n=TOP_N):\n",
    "    out = []\n",
    "    for (c, coll), sub in df_sig.groupby([\"contrast\",\"collection\"]):\n",
    "        sub = sub.sort_values([\"FDR_q\",\"NES\"], ascending=[True, False]).head(top_n).copy()\n",
    "        out.append(sub)\n",
    "    return pd.concat(out, ignore_index=True) if out else pd.DataFrame()\n",
    "\n",
    "topN = top_by_contrast(sig, TOP_N)\n",
    "topN_out = topN[[\n",
    "    \"collection\",\"contrast\",\"group_first\",\"group_second\",\n",
    "    \"Term_display\",\"NES\",\"FDR_q\",\"Direction\",\"set_size\",\"lead_n\",\"lead_preview\"\n",
    "]].rename(columns={\"Term_display\":\"Term\"})\n",
    "topN_out.to_csv(OUT_DIR / \"GSEA_top_terms_with_genes.csv\", index=False)\n",
    "\n",
    "# Also dump full membership per top row (separate wide file to avoid huge CSV above)\n",
    "mem_rows = []\n",
    "for _, r in topN.iterrows():\n",
    "    mem_rows.append({\n",
    "        \"collection\": r[\"collection\"],\n",
    "        \"contrast\": r[\"contrast\"],\n",
    "        \"Term\": r[\"Term_display\"],\n",
    "        \"set_size\": r[\"set_size\"],\n",
    "        \"members\": \";\".join(r[\"members\"]),\n",
    "        \"leading_edge\": \";\".join(r[\"lead_genes_list\"]) if isinstance(r[\"lead_genes_list\"], list) else \"\"\n",
    "    })\n",
    "pd.DataFrame(mem_rows).to_csv(OUT_DIR / \"GSEA_top_terms_membership.csv\", index=False)\n",
    "\n",
    "# ------------------ Build driver gene bags & overlaps (vs Mock only) ------------------\n",
    "def driver_bag(df_sig: pd.DataFrame, contrast: str, direction: str) -> set[str]:\n",
    "    a, b = groups_of(contrast)\n",
    "    sub = df_sig[(df_sig[\"contrast\"]==contrast) & (df_sig[\"NES\"].notna())]\n",
    "    sub = sub[sub[\"NES\"] > 0] if direction==\"up\" else sub[sub[\"NES\"] < 0]\n",
    "    # union of leading-edge genes across all significant terms (any collection)\n",
    "    genes = set()\n",
    "    for xs in sub[\"lead_genes_list\"]:\n",
    "        if isinstance(xs, list):\n",
    "            genes.update(xs)\n",
    "    return genes\n",
    "\n",
    "vs_mock = [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\"]\n",
    "\n",
    "bags_up   = {c: driver_bag(sig, c, \"up\")   for c in vs_mock}\n",
    "bags_down = {c: driver_bag(sig, c, \"down\") for c in vs_mock}\n",
    "\n",
    "# Save bags\n",
    "(OUT_DIR / \"driver_bags\").mkdir(exist_ok=True)\n",
    "for c in vs_mock:\n",
    "    pd.Series(sorted(bags_up[c])).to_csv(OUT_DIR / \"driver_bags\" / f\"drivers_UP_{c}.txt\", index=False, header=False)\n",
    "    pd.Series(sorted(bags_down[c])).to_csv(OUT_DIR / \"driver_bags\" / f\"drivers_DOWN_{c}.txt\", index=False, header=False)\n",
    "\n",
    "# Overlap/unique summary\n",
    "def overlap_summary(bags: dict[str, set[str]], label: str):\n",
    "    cs = list(bags.keys())\n",
    "    A, B, C = cs\n",
    "    a, b, c = bags[A], bags[B], bags[C]\n",
    "    summary = {\n",
    "        f\"unique_{A}\": sorted(a - b - c),\n",
    "        f\"unique_{B}\": sorted(b - a - c),\n",
    "        f\"unique_{C}\": sorted(c - a - b),\n",
    "        f\"shared_{A}_{B}\": sorted((a & b) - c),\n",
    "        f\"shared_{A}_{C}\": sorted((a & c) - b),\n",
    "        f\"shared_{B}_{C}\": sorted((b & c) - a),\n",
    "        f\"shared_all\": sorted(a & b & c),\n",
    "    }\n",
    "    # counts table\n",
    "    counts = pd.DataFrame({\n",
    "        \"set\": list(summary.keys()),\n",
    "        \"n_genes\": [len(v) for v in summary.values()]\n",
    "    })\n",
    "    # write\n",
    "    prefix = OUT_DIR / f\"drivers_overlap_{label}\"\n",
    "    counts.to_csv(prefix + \"_counts.csv\", index=False)\n",
    "    # detailed lists\n",
    "    with open(prefix + \"_lists.json\", \"w\") as fh:\n",
    "        json.dump(summary, fh, indent=2)\n",
    "    # also explode to CSV\n",
    "    long = []\n",
    "    for k, genes in summary.items():\n",
    "        for g in genes:\n",
    "            long.append({\"group\": k, \"gene\": g})\n",
    "    pd.DataFrame(long).to_csv(prefix + \"_lists.csv\", index=False)\n",
    "    print(f\"[OK] Overlap ({label}) -> {prefix+'_counts.csv'} & {prefix+'_lists.*'}\")# --- replace your overlap_summary with this ---\n",
    "    \n",
    "def overlap_summary(bags: dict, label: str):\n",
    "    cs = list(bags.keys())\n",
    "    if len(cs) != 3:\n",
    "        raise ValueError(\"Expected exactly 3 contrasts in bags (Bt_vs_Mock, Cd_vs_Mock, Co_vs_Mock).\")\n",
    "    A, B, C = cs\n",
    "    a, b, c = bags[A], bags[B], bags[C]\n",
    "\n",
    "    summary = {\n",
    "        f\"unique_{A}\": sorted(a - b - c),\n",
    "        f\"unique_{B}\": sorted(b - a - c),\n",
    "        f\"unique_{C}\": sorted(c - a - b),\n",
    "        f\"shared_{A}_{B}\": sorted((a & b) - c),\n",
    "        f\"shared_{A}_{C}\": sorted((a & c) - b),\n",
    "        f\"shared_{B}_{C}\": sorted((b & c) - a),\n",
    "        f\"shared_all\": sorted(a & b & c),\n",
    "    }\n",
    "\n",
    "    # counts table\n",
    "    counts = pd.DataFrame({\n",
    "        \"set\": list(summary.keys()),\n",
    "        \"n_genes\": [len(v) for v in summary.values()]\n",
    "    })\n",
    "\n",
    "    # build file paths correctly (Path, not string concatenation)\n",
    "    counts_path = OUT_DIR / f\"drivers_overlap_{label}_counts.csv\"\n",
    "    lists_json_path = OUT_DIR / f\"drivers_overlap_{label}_lists.json\"\n",
    "    lists_csv_path  = OUT_DIR / f\"drivers_overlap_{label}_lists.csv\"\n",
    "\n",
    "    counts.to_csv(counts_path, index=False)\n",
    "\n",
    "    # detailed lists\n",
    "    with open(lists_json_path, \"w\") as fh:\n",
    "        json.dump(summary, fh, indent=2)\n",
    "\n",
    "    long = []\n",
    "    for k, genes in summary.items():\n",
    "        for g in genes:\n",
    "            long.append({\"group\": k, \"gene\": g})\n",
    "    pd.DataFrame(long).to_csv(lists_csv_path, index=False)\n",
    "\n",
    "    print(f\"[OK] Overlap ({label}) -> {counts_path} & {lists_csv_path}\")\n",
    "\n",
    "\n",
    "overlap_summary(bags_up,   label=\"UP\")\n",
    "overlap_summary(bags_down, label=\"DOWN\")\n",
    "\n",
    "print(\"\\n[OK] Wrote:\")\n",
    "print(\" -\", OUT_DIR / \"GSEA_top_terms_with_genes.csv\")\n",
    "print(\" -\", OUT_DIR / \"GSEA_top_terms_membership.csv\")\n",
    "print(\" -\", OUT_DIR / \"driver_bags/ (UP/DOWN txt lists)\")\n",
    "print(\" -\", OUT_DIR / \"drivers_overlap_UP_counts.csv and _lists.(csv|json)\")\n",
    "print(\" -\", OUT_DIR / \"drivers_overlap_DOWN_counts.csv and _lists.(csv|json)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16893d4f-3d1e-42ea-838c-61c17fedb621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38389cf3-7e18-488e-a913-a601bcced4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote:\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/GSEA_DEG_overlap_top_pathways_and_genes.csv\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/overlap_tables  (per-pathway detailed gene tables)\n",
      " - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA/summary/GSEA_DEG_overlap_long_per_pathway_gene.csv\n"
     ]
    }
   ],
   "source": [
    "# ==== GSEA x DEG overlap summary ====\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, re\n",
    "\n",
    "# ---------- config ----------\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "ANALYSIS_DIR = BASE / \"analysis\"\n",
    "DE_DIR  = ANALYSIS_DIR / \"DE\"\n",
    "GSEA_DIR = ANALYSIS_DIR / \"GSEA\"\n",
    "OUT_DIR  = GSEA_DIR / \"summary\"\n",
    "TAB_DIR  = OUT_DIR / \"overlap_tables\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TAB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "contrasts = [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\",\"Bt_vs_Cd\",\"Bt_vs_Co\",\"Cd_vs_Co\"]\n",
    "collections = {\n",
    "    \"reactome\": {\"subdir\": \"reactome\", \"fname\": \"gsea_reactome_results.csv\"},\n",
    "    \"kegg\":     {\"subdir\": \"kegg\",     \"fname\": \"gsea_kegg_results.csv\"},\n",
    "    \"hallmark\": {\"subdir\": \"hallmark\", \"fname\": \"gsea_hallmark_results.csv\"},\n",
    "}\n",
    "PATHWAY_FDR = 0.05           # pathway significance filter\n",
    "TOP_PATHWAYS = 10            # number of pathways per contrast x collection to report\n",
    "TOP_GENES = 10               # number of genes to show for each pathway\n",
    "DE_FDR = 0.05                # DEG significance when picking driving genes\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def read_any_csv(p: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(p, sep=None, engine=\"python\")\n",
    "\n",
    "def pick_col(cols_lower, patterns):\n",
    "    for pat in patterns:  # prefer specific patterns first\n",
    "        for cl, co in cols_lower.items():\n",
    "            if re.search(pat, cl, flags=re.I):\n",
    "                return co\n",
    "    return None\n",
    "\n",
    "def std_gsea(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cl = {c.lower(): c for c in df.columns}\n",
    "    term = pick_col(cl, [r\"^term$\", r\"description\", r\"^pathway$\", r\"^gs$\", r\"^name$\"])\n",
    "    nes  = pick_col(cl, [r\"^nes$\", r\"normalized[ _-]?enrichment\"])\n",
    "    fdr  = pick_col(cl, [r\"^fdr(_?q)?$\", r\"fdr[ _-]?q[ _-]?val(ue)?\", r\"^q[ _-]?val\"])\n",
    "    pvl  = pick_col(cl, [r\"^pval$\", r\"^p[-_ ]?value$\", r\"^p$\", r\"^nom.*p.*val\"])\n",
    "    led  = pick_col(cl, [r\"^lead.*gene\", r\"leading.*edge\", r\"ledge.*gene\", r\"^genes$\", r\"^hits$\"])\n",
    "    out = pd.DataFrame()\n",
    "    if term is not None: out[\"Term\"] = df[term].astype(str)\n",
    "    if nes  is not None: out[\"NES\"]  = pd.to_numeric(df[nes], errors=\"coerce\")\n",
    "    if fdr  is not None: out[\"FDR_q\"]= pd.to_numeric(df[fdr], errors=\"coerce\")\n",
    "    if pvl  is not None: out[\"pval\"] = pd.to_numeric(df[pvl], errors=\"coerce\")\n",
    "    if led  is not None: out[\"lead_genes\"] = df[led].astype(str)\n",
    "    return out\n",
    "\n",
    "SPLIT = re.compile(r\"[;,\\|/\\s]+\")\n",
    "def parse_leading_edge_cell(x: str):\n",
    "    if not isinstance(x, str) or not x.strip():\n",
    "        return []\n",
    "    toks = [t for t in SPLIT.split(x) if t]\n",
    "    return [t for t in toks if re.match(r\"^[A-Za-z0-9_.\\-]+$\", t)]\n",
    "\n",
    "def load_gmt(path: Path):\n",
    "    mem = {}\n",
    "    if not path.exists(): return mem\n",
    "    with path.open() as fh:\n",
    "        for line in fh:\n",
    "            parts = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            if len(parts) >= 3:\n",
    "                mem[parts[0]] = [g for g in parts[2:] if g]\n",
    "    return mem\n",
    "\n",
    "def keyify(s: str) -> str:\n",
    "    return re.sub(r\"[\\s_]+\", \" \", s.strip()).lower()\n",
    "\n",
    "def members_from_gmt(mem: dict, term_raw: str, term_disp: str):\n",
    "    # exact raw\n",
    "    if term_raw in mem: return mem[term_raw]\n",
    "    # rebuild typical prefixed forms from display\n",
    "    disp_up = term_disp.replace(\" \", \"_\").upper()\n",
    "    for pref in (\"REACTOME_\", \"HALLMARK_\"):\n",
    "        cand = pref + disp_up\n",
    "        if cand in mem: return mem[cand]\n",
    "    # relaxed key match\n",
    "    bykey = {keyify(k): v for k, v in mem.items()}\n",
    "    for cand in (term_raw, term_disp):\n",
    "        v = bykey.get(keyify(cand))\n",
    "        if v: return v\n",
    "    return []\n",
    "\n",
    "def clean_term(s: str) -> str:\n",
    "    return (s.replace(\"REACTOME_\", \"\")\n",
    "             .replace(\"HALLMARK_\", \"\")\n",
    "             .replace(\"_\", \" \"))\n",
    "\n",
    "def safe_filename(s: str) -> str:\n",
    "    s = re.sub(r\"[^\\w\\-]+\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "# ---------- main ----------\n",
    "overview_rows = []\n",
    "long_rows = []\n",
    "\n",
    "for contrast in contrasts:\n",
    "    # load DEG table\n",
    "    de_path = DE_DIR / f\"python_voomlite_{contrast}.csv\"\n",
    "    if not de_path.exists():\n",
    "        print(f\"[WARN] DEG missing for {contrast}: {de_path}\")\n",
    "        continue\n",
    "    deg = pd.read_csv(de_path)\n",
    "    # standardize columns\n",
    "    assert {\"gene_symbol\",\"logFC\",\"padj\"}.issubset(deg.columns), f\"DE file missing cols in {de_path}\"\n",
    "    deg[\"gene_symbol\"] = deg[\"gene_symbol\"].astype(str)\n",
    "    deg[\"is_sig\"] = (pd.to_numeric(deg[\"padj\"], errors=\"coerce\") < DE_FDR)\n",
    "\n",
    "    for coll, info in collections.items():\n",
    "        base = GSEA_DIR / info[\"subdir\"] / contrast\n",
    "        main = base / info[\"fname\"]\n",
    "        alt  = base / \"gseapy.gene_set.prerank.report.csv\"\n",
    "        gsea_file = main if main.exists() else (alt if alt.exists() else None)\n",
    "        if gsea_file is None:\n",
    "            print(f\"[WARN] GSEA missing for {coll} {contrast}\")\n",
    "            continue\n",
    "\n",
    "        gdf_raw = read_any_csv(gsea_file)\n",
    "        gdf = std_gsea(gdf_raw)\n",
    "        if gdf.empty or \"Term\" not in gdf.columns or \"NES\" not in gdf.columns:\n",
    "            print(f\"[WARN] Unrecognized GSEA format for {coll} {contrast}: {gsea_file}\")\n",
    "            continue\n",
    "\n",
    "        # ensure FDR_q\n",
    "        if \"FDR_q\" not in gdf.columns or gdf[\"FDR_q\"].isna().all():\n",
    "            from statsmodels.stats.multitest import multipletests\n",
    "            if \"pval\" in gdf.columns:\n",
    "                gdf[\"FDR_q\"] = multipletests(gdf[\"pval\"].fillna(1.0), method=\"fdr_bh\")[1]\n",
    "            else:\n",
    "                gdf[\"FDR_q\"] = np.nan\n",
    "\n",
    "        gdf[\"Term_display\"] = gdf[\"Term\"].astype(str).map(clean_term)\n",
    "        gdf[\"lead_list\"] = gdf.get(\"lead_genes\", pd.Series([\"\"]*len(gdf))).apply(parse_leading_edge_cell)\n",
    "\n",
    "        # fallback to GMT membership if no leading-edge available\n",
    "        gmt_path = base / \"gene_sets.gmt\"\n",
    "        gmt_mem = load_gmt(gmt_path)\n",
    "\n",
    "        # filter & pick top pathways\n",
    "        sel = gdf[(pd.to_numeric(gdf[\"FDR_q\"], errors=\"coerce\") < PATHWAY_FDR) & gdf[\"NES\"].notna()]\n",
    "        sel = sel.sort_values([\"FDR_q\",\"NES\"], ascending=[True, False]).head(TOP_PATHWAYS).copy()\n",
    "        if sel.empty:\n",
    "            continue\n",
    "\n",
    "        for _, r in sel.iterrows():\n",
    "            term_raw  = str(r[\"Term\"])\n",
    "            term_disp = str(r[\"Term_display\"])\n",
    "            nes  = float(r[\"NES\"])\n",
    "            qval = float(r[\"FDR_q\"])\n",
    "\n",
    "            lead = r[\"lead_list\"]\n",
    "            if not lead:  # fallback to entire set membership, then pick DE drivers\n",
    "                lead = members_from_gmt(gmt_mem, term_raw, term_disp)\n",
    "\n",
    "            # match to DEG by gene_symbol\n",
    "            if not lead:\n",
    "                matched = pd.DataFrame(columns=[\"gene_symbol\",\"logFC\",\"padj\",\"is_sig\"])\n",
    "            else:\n",
    "                m = pd.DataFrame({\"gene_symbol\": list(dict.fromkeys(lead))})\n",
    "                matched = m.merge(deg[[\"gene_symbol\",\"logFC\",\"padj\",\"is_sig\"]],\n",
    "                                  on=\"gene_symbol\", how=\"left\")\n",
    "\n",
    "            # choose top drivers among leading-edge: prefer significant, then by padj then |logFC|\n",
    "            matched[\"padj\"] = pd.to_numeric(matched[\"padj\"], errors=\"coerce\")\n",
    "            matched[\"logFC\"] = pd.to_numeric(matched[\"logFC\"], errors=\"coerce\")\n",
    "            matched[\"rank_sig\"] = (~matched[\"is_sig\"]).astype(int)  # 0 for sig first\n",
    "            matched = matched.sort_values(\n",
    "                [\"rank_sig\",\"padj\",\"logFC\"],\n",
    "                ascending=[True, True, False],\n",
    "                na_position=\"last\"\n",
    "            )\n",
    "            top_genes = matched.head(TOP_GENES).copy()\n",
    "\n",
    "            # summary row for overview\n",
    "            gene_str = \"; \".join([\n",
    "                f\"{g} (log2FC={lfc:+.2f}, q={q:.3g})\"\n",
    "                for g, lfc, q in zip(\n",
    "                    top_genes[\"gene_symbol\"].fillna(\"NA\"),\n",
    "                    top_genes[\"logFC\"].fillna(np.nan),\n",
    "                    top_genes[\"padj\"].fillna(np.nan)\n",
    "                )\n",
    "            ])\n",
    "            overview_rows.append({\n",
    "                \"contrast\": contrast,\n",
    "                \"collection\": coll,\n",
    "                \"pathway\": term_disp,\n",
    "                \"NES\": nes,\n",
    "                \"FDR_q\": qval,\n",
    "                \"n_leading_edge\": int(len(lead)),\n",
    "                \"n_leading_edge_sig\": int(matched[\"is_sig\"].fillna(False).sum()),\n",
    "                \"top_genes\": gene_str\n",
    "            })\n",
    "\n",
    "            # detailed table per pathway\n",
    "            det = matched.loc[:, [\"gene_symbol\",\"logFC\",\"padj\",\"is_sig\"]].copy()\n",
    "            det.insert(0, \"collection\", coll)\n",
    "            det.insert(1, \"contrast\", contrast)\n",
    "            det.insert(2, \"pathway\", term_disp)\n",
    "            # write per-pathway file\n",
    "            fname = f\"{safe_filename(contrast)}__{safe_filename(coll)}__{safe_filename(term_disp)}.csv\"\n",
    "            det.to_csv(TAB_DIR / fname, index=False)\n",
    "            # collect long (optional)\n",
    "            for _, rr in det.iterrows():\n",
    "                long_rows.append({\n",
    "                    \"contrast\": contrast,\n",
    "                    \"collection\": coll,\n",
    "                    \"pathway\": term_disp,\n",
    "                    \"gene_symbol\": rr[\"gene_symbol\"],\n",
    "                    \"logFC\": rr[\"logFC\"],\n",
    "                    \"padj\": rr[\"padj\"],\n",
    "                    \"is_sig\": rr[\"is_sig\"]\n",
    "                })\n",
    "\n",
    "# write outputs\n",
    "overview_df = pd.DataFrame(overview_rows).sort_values(\n",
    "    [\"contrast\",\"collection\",\"FDR_q\",\"NES\"],\n",
    "    ascending=[True, True, True, False]\n",
    ")\n",
    "overview_path = OUT_DIR / \"GSEA_DEG_overlap_top_pathways_and_genes.csv\"\n",
    "overview_df.to_csv(overview_path, index=False)\n",
    "\n",
    "if long_rows:\n",
    "    long_df = pd.DataFrame(long_rows)\n",
    "    long_df.to_csv(OUT_DIR / \"GSEA_DEG_overlap_long_per_pathway_gene.csv\", index=False)\n",
    "\n",
    "print(\"[OK] Wrote:\")\n",
    "print(\" -\", overview_path)\n",
    "print(\" -\", TAB_DIR, \" (per-pathway detailed gene tables)\")\n",
    "if long_rows:\n",
    "    print(\" -\", OUT_DIR / \"GSEA_DEG_overlap_long_per_pathway_gene.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbb767-40c2-4565-b9d0-37d32ae5f4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Bt_vs_Mock ->\n",
      "    Bt_vs_Mock.summary.md Bt_vs_Mock.top_pathways_UP.csv Bt_vs_Mock.top_pathways_DOWN.csv Bt_vs_Mock.top_genes_UP.csv Bt_vs_Mock.top_genes_DOWN.csv\n",
      "[OK] Cd_vs_Mock ->\n",
      "    Cd_vs_Mock.summary.md Cd_vs_Mock.top_pathways_UP.csv Cd_vs_Mock.top_pathways_DOWN.csv Cd_vs_Mock.top_genes_UP.csv Cd_vs_Mock.top_genes_DOWN.csv\n",
      "[OK] Co_vs_Mock ->\n",
      "    Co_vs_Mock.summary.md Co_vs_Mock.top_pathways_UP.csv Co_vs_Mock.top_pathways_DOWN.csv Co_vs_Mock.top_genes_UP.csv Co_vs_Mock.top_genes_DOWN.csv\n",
      "[OK] Bt_vs_Cd ->\n",
      "    Bt_vs_Cd.summary.md Bt_vs_Cd.top_pathways_UP.csv Bt_vs_Cd.top_pathways_DOWN.csv Bt_vs_Cd.top_genes_UP.csv Bt_vs_Cd.top_genes_DOWN.csv\n"
     ]
    }
   ],
   "source": [
    "# ==== Compact GSEA x DEG per-condition summaries ====\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, List\n",
    "import pandas as pd, numpy as np, re\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ------------------ Config ------------------\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "ANALYSIS_DIR = BASE / \"analysis\"\n",
    "DE_DIR   = ANALYSIS_DIR / \"DE\"\n",
    "GSEA_DIR = ANALYSIS_DIR / \"GSEA\"\n",
    "OUT_DIR  = GSEA_DIR / \"summary\" / \"compact\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# contrasts to summarize\n",
    "CONTRASTS = [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\",\"Bt_vs_Cd\",\"Bt_vs_Co\",\"Cd_vs_Co\"]\n",
    "COLLECTIONS = {\n",
    "    \"reactome\": {\"subdir\": \"reactome\", \"fname\": \"gsea_reactome_results.csv\"},\n",
    "    \"kegg\":     {\"subdir\": \"kegg\",     \"fname\": \"gsea_kegg_results.csv\"},\n",
    "    \"hallmark\": {\"subdir\": \"hallmark\", \"fname\": \"gsea_hallmark_results.csv\"},\n",
    "}\n",
    "ALT_REPORT = \"gseapy.gene_set.prerank.report.csv\"   # fallback inside each contrast folder\n",
    "\n",
    "# knobs\n",
    "PATHWAY_FDR   = 0.09    # significance for pathways\n",
    "TOP_PATHWAYS  = 5       # how many UP/DOWN pathways to show (overall, across collections)\n",
    "TOP_GENES     = 10      # how many UP/DOWN driver genes to show\n",
    "DE_FDR        = 0.05    # significance tag for DEG\n",
    "WEIGHT_FLOOR  = 1e-300  # prevent log(0)\n",
    "\n",
    "# ------------------ Helpers ------------------\n",
    "def read_any_csv(p: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(p, sep=None, engine=\"python\")\n",
    "\n",
    "def _pick_col(cols_lower, patterns):\n",
    "    for pat in patterns:\n",
    "        for cl, co in cols_lower.items():\n",
    "            if re.search(pat, cl, flags=re.I):\n",
    "                return co\n",
    "    return None\n",
    "\n",
    "def std_gsea(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cl = {c.lower(): c for c in df.columns}\n",
    "    term = _pick_col(cl, [r\"^term$\", r\"description\", r\"^pathway$\", r\"^gs$\", r\"^name$\"])\n",
    "    nes  = _pick_col(cl, [r\"^nes$\", r\"normalized[ _-]?enrichment\"])\n",
    "    fdr  = _pick_col(cl, [r\"^fdr(_?q)?$\", r\"fdr[ _-]?q[ _-]?val(ue)?\", r\"^q[ _-]?val\"])\n",
    "    pvl  = _pick_col(cl, [r\"^pval$\", r\"^p[-_ ]?value$\", r\"^p$\", r\"^nom.*p.*val\"])\n",
    "    led  = _pick_col(cl, [r\"^lead.*gene\", r\"leading.*edge\", r\"ledge.*gene\", r\"^genes$\", r\"^hits$\"])\n",
    "\n",
    "    out = pd.DataFrame()\n",
    "    if term is not None: out[\"Term\"] = df[term].astype(str)\n",
    "    if nes  is not None: out[\"NES\"]  = pd.to_numeric(df[nes], errors=\"coerce\")\n",
    "    if fdr  is not None: out[\"FDR_q\"]= pd.to_numeric(df[fdr], errors=\"coerce\")\n",
    "    if pvl  is not None: out[\"pval\"] = pd.to_numeric(df[pvl], errors=\"coerce\")\n",
    "    if led  is not None: out[\"lead_genes\"] = df[led].astype(str)\n",
    "    return out\n",
    "\n",
    "def load_gmt(path: Path) -> Dict[str, List[str]]:\n",
    "    mem: Dict[str, List[str]] = {}\n",
    "    if not path.exists(): return mem\n",
    "    with path.open() as fh:\n",
    "        for line in fh:\n",
    "            parts = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            if len(parts) >= 3:\n",
    "                mem[parts[0]] = [g for g in parts[2:] if g]\n",
    "    return mem\n",
    "\n",
    "def keyify(s: str) -> str:\n",
    "    return re.sub(r\"[\\s_]+\", \" \", s.strip()).lower()\n",
    "\n",
    "def members_from_gmt(mem: Dict[str, List[str]], term_raw: str, term_disp: str):\n",
    "    # exact raw\n",
    "    if term_raw in mem: return mem[term_raw]\n",
    "    # rebuild prefixed forms from display name\n",
    "    disp_up = term_disp.replace(\" \", \"_\").upper()\n",
    "    for pref in (\"REACTOME_\", \"HALLMARK_\"):\n",
    "        cand = pref + disp_up\n",
    "        if cand in mem: return mem[cand]\n",
    "    # relaxed key match\n",
    "    bykey = {keyify(k): v for k, v in mem.items()}\n",
    "    for cand in (term_raw, term_disp):\n",
    "        v = bykey.get(keyify(cand))\n",
    "        if v: return v\n",
    "    return []\n",
    "\n",
    "_SPLIT = re.compile(r\"[;,\\|/\\s]+\")\n",
    "def parse_leading_edge_cell(x: str):\n",
    "    if not isinstance(x, str) or not x.strip(): return []\n",
    "    toks = [t for t in _SPLIT.split(x) if t]\n",
    "    return [t for t in toks if re.match(r\"^[A-Za-z0-9_.\\-]+$\", t)]\n",
    "\n",
    "def clean_term(s: str) -> str:\n",
    "    return (s.replace(\"REACTOME_\", \"\")\n",
    "             .replace(\"HALLMARK_\", \"\")\n",
    "             .replace(\"_\", \" \"))\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    s = re.sub(r\"[^\\w\\-]+\", \"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "def groups_of(contrast: str):\n",
    "    return contrast.split(\"_vs_\", 1) if \"_vs_\" in contrast else contrast.split(\"vs\", 1)\n",
    "\n",
    "# per-gene weight from a pathway row (for ranking driver genes)\n",
    "def pathway_weight(nes: float, fdr: float) -> float:\n",
    "    return abs(float(nes)) * (-np.log10(max(float(fdr), WEIGHT_FLOOR)))\n",
    "\n",
    "# ------------------ Run per contrast ------------------\n",
    "overview_all = []  # one line per pathway kept (for an all-conditions sheet)\n",
    "\n",
    "for contrast in CONTRASTS:\n",
    "    # 1) DEG\n",
    "    de_path = DE_DIR / f\"python_voomlite_{contrast}.csv\"\n",
    "    if not de_path.exists():\n",
    "        print(f\"[WARN] DEG missing for {contrast}: {de_path}\")\n",
    "        continue\n",
    "    deg = pd.read_csv(de_path)\n",
    "    if not {\"gene_symbol\",\"logFC\",\"padj\"}.issubset(deg.columns):\n",
    "        print(f\"[WARN] DEG columns missing in {de_path}, skipping.\")\n",
    "        continue\n",
    "    deg[\"gene_symbol\"] = deg[\"gene_symbol\"].astype(str)\n",
    "    deg[\"padj\"] = pd.to_numeric(deg[\"padj\"], errors=\"coerce\")\n",
    "    deg[\"logFC\"] = pd.to_numeric(deg[\"logFC\"], errors=\"coerce\")\n",
    "    deg[\"is_sig\"] = deg[\"padj\"] < DE_FDR\n",
    "\n",
    "    # 2) GSEA (collect all collections)\n",
    "    gsea_rows = []\n",
    "    members_cache = {}  # (collection) -> membership dict\n",
    "    for coll, info in COLLECTIONS.items():\n",
    "        base = GSEA_DIR / info[\"subdir\"] / contrast\n",
    "        main = base / info[\"fname\"]\n",
    "        alt  = base / ALT_REPORT\n",
    "        usef = main if main.exists() else (alt if alt.exists() else None)\n",
    "        if usef is None:\n",
    "            continue\n",
    "\n",
    "        gdf_raw = read_any_csv(usef)\n",
    "        gdf = std_gsea(gdf_raw)\n",
    "        if gdf.empty or \"Term\" not in gdf.columns or \"NES\" not in gdf.columns:\n",
    "            continue\n",
    "\n",
    "        # ensure FDR_q\n",
    "        if \"FDR_q\" not in gdf.columns or gdf[\"FDR_q\"].isna().all():\n",
    "            if \"pval\" in gdf.columns:\n",
    "                gdf[\"FDR_q\"] = multipletests(gdf[\"pval\"].fillna(1.0), method=\"fdr_bh\")[1]\n",
    "            else:\n",
    "                gdf[\"FDR_q\"] = np.nan\n",
    "\n",
    "        gdf[\"collection\"]  = coll\n",
    "        gdf[\"Term_raw\"]    = gdf[\"Term\"].astype(str)\n",
    "        gdf[\"Term\"]        = gdf[\"Term_raw\"].map(clean_term)\n",
    "        gdf[\"lead_list\"]   = gdf.get(\"lead_genes\", pd.Series([\"\"]*len(gdf))).apply(parse_leading_edge_cell)\n",
    "\n",
    "        gsea_rows.append(gdf)\n",
    "\n",
    "        # cache membership dict\n",
    "        if coll not in members_cache:\n",
    "            members_cache[coll] = load_gmt(base / \"gene_sets.gmt\")\n",
    "\n",
    "    if not gsea_rows:\n",
    "        print(f\"[WARN] No GSEA rows for {contrast}\")\n",
    "        continue\n",
    "    gsea_all = pd.concat(gsea_rows, ignore_index=True)\n",
    "\n",
    "    # 3) filter significant pathways & pick compact top UP/DOWN overall\n",
    "    sig = gsea_all[(gsea_all[\"NES\"].notna()) & (gsea_all[\"FDR_q\"].notna()) & (gsea_all[\"FDR_q\"] < PATHWAY_FDR)].copy()\n",
    "    if sig.empty:\n",
    "        print(f\"[INFO] No pathways at FDR<{PATHWAY_FDR} for {contrast}. Skipping summary.\")\n",
    "        continue\n",
    "\n",
    "    sig[\"Direction\"] = np.where(sig[\"NES\"]>0, \"UP\", \"DOWN\")\n",
    "    # rank: FDR asc, then |NES| desc\n",
    "    sig = sig.sort_values([\"FDR_q\",\"NES\"], ascending=[True, False])\n",
    "\n",
    "    top_up   = sig[sig[\"NES\"]>0].head(TOP_PATHWAYS).copy()\n",
    "    top_down = sig[sig[\"NES\"]<0].sort_values([\"FDR_q\",\"NES\"], ascending=[True, True]).head(TOP_PATHWAYS).copy()\n",
    "\n",
    "    # 4) build driver genes per direction from TOP pathways only (keeps it compact)\n",
    "    def drivers_from(top_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        if top_df.empty: \n",
    "            return pd.DataFrame(columns=[\"gene_symbol\",\"driver_score\",\"log2FC\",\"q\"])\n",
    "        # assemble gene->weight sum\n",
    "        weights = {}\n",
    "        for _, r in top_df.iterrows():\n",
    "            term = r[\"Term\"]\n",
    "            coll = r[\"collection\"]\n",
    "            nes  = float(r[\"NES\"]); q = float(r[\"FDR_q\"])\n",
    "            w    = pathway_weight(nes, q)\n",
    "\n",
    "            lead = r[\"lead_list\"]\n",
    "            if not lead:  # fallback to full membership from GMT\n",
    "                mem = members_cache.get(coll, {})\n",
    "                lead = members_from_gmt(mem, r[\"Term_raw\"], term)\n",
    "\n",
    "            for g in set(lead):\n",
    "                weights[g] = weights.get(g, 0.0) + w\n",
    "\n",
    "        if not weights:\n",
    "            return pd.DataFrame(columns=[\"gene_symbol\",\"driver_score\",\"log2FC\",\"q\"])\n",
    "\n",
    "        drv = (pd.DataFrame(list(weights.items()), columns=[\"gene_symbol\",\"driver_score\"])\n",
    "                 .sort_values(\"driver_score\", ascending=False))\n",
    "\n",
    "        # join DEG stats\n",
    "        drv = drv.merge(deg[[\"gene_symbol\",\"logFC\",\"padj\"]], on=\"gene_symbol\", how=\"left\")\n",
    "        drv.rename(columns={\"logFC\":\"log2FC\",\"padj\":\"q\"}, inplace=True)\n",
    "        # order by driver_score, then q, then |log2FC|\n",
    "        drv[\"q\"] = pd.to_numeric(drv[\"q\"], errors=\"coerce\")\n",
    "        drv[\"log2FC\"] = pd.to_numeric(drv[\"log2FC\"], errors=\"coerce\")\n",
    "        drv = drv.sort_values([\"driver_score\",\"q\",\"log2FC\"], ascending=[False, True, False])\n",
    "        return drv\n",
    "\n",
    "    drv_up   = drivers_from(top_up).head(TOP_GENES)\n",
    "    drv_down = drivers_from(top_down).head(TOP_GENES)\n",
    "\n",
    "    # 5) write tiny CSVs + markdown one-pager\n",
    "    a, b = groups_of(contrast)\n",
    "    pre = OUT_DIR / f\"{safe_name(contrast)}\"\n",
    "\n",
    "    # pathways tables\n",
    "    pu = top_up.loc[:, [\"collection\",\"Term\",\"NES\",\"FDR_q\"]].copy()\n",
    "    pdn = top_down.loc[:, [\"collection\",\"Term\",\"NES\",\"FDR_q\"]].copy()\n",
    "    pu.to_csv(pre.with_suffix(\".top_pathways_UP.csv\"), index=False)\n",
    "    pdn.to_csv(pre.with_suffix(\".top_pathways_DOWN.csv\"), index=False)\n",
    "\n",
    "    # driver genes tables\n",
    "    drv_up.to_csv(pre.with_suffix(\".top_genes_UP.csv\"), index=False)\n",
    "    drv_down.to_csv(pre.with_suffix(\".top_genes_DOWN.csv\"), index=False)\n",
    "\n",
    "    # overview (also collect for a global sheet)\n",
    "    for df, direction in [(top_up,\"UP\"), (top_down,\"DOWN\")]:\n",
    "        for _, r in df.iterrows():\n",
    "            overview_all.append({\n",
    "                \"contrast\": contrast,\n",
    "                \"direction\": direction,\n",
    "                \"collection\": r[\"collection\"],\n",
    "                \"pathway\": r[\"Term\"],\n",
    "                \"NES\": float(r[\"NES\"]),\n",
    "                \"FDR_q\": float(r[\"FDR_q\"]),\n",
    "            })\n",
    "\n",
    "    # markdown one-pager\n",
    "    def fmt_pathways(df, dirlabel):\n",
    "        if df.empty: return f\"_No significant pathways {dirlabel.lower()}._\\n\"\n",
    "        lines = []\n",
    "        for _, r in df.iterrows():\n",
    "            lines.append(f\"- [{r['collection']}] **{r['Term']}** (NES {r['NES']:.2f}, q {r['FDR_q']:.3g})\")\n",
    "        return \"\\n\".join(lines) + \"\\n\"\n",
    "\n",
    "    def fmt_genes(df, dirlabel):\n",
    "        if df.empty: return f\"_No driver genes {dirlabel.lower()}._\\n\"\n",
    "        parts = []\n",
    "        for _, r in df.iterrows():\n",
    "            g = r[\"gene_symbol\"]; lfc = r[\"log2FC\"]; q = r[\"q\"]\n",
    "            parts.append(f\"**{g}** (log2FC {lfc:+.2f}, q {q:.3g})\")\n",
    "        return \", \".join(parts) + \"\\n\"\n",
    "\n",
    "    md = []\n",
    "    md.append(f\"# {contrast}: compact summary\\n\")\n",
    "    md.append(f\"_Up = enriched in **{a}**; Down = enriched in **{b}**._\\n\")\n",
    "    md.append(f\"## Top pathways — UP in {a}\\n\")\n",
    "    md.append(fmt_pathways(pu, \"UP\"))\n",
    "    md.append(f\"## Top driver genes — UP in {a}\\n\")\n",
    "    md.append(fmt_genes(drv_up, \"UP\"))\n",
    "    md.append(f\"## Top pathways — DOWN in {b}\\n\")\n",
    "    md.append(fmt_pathways(pdn, \"DOWN\"))\n",
    "    md.append(f\"## Top driver genes — DOWN in {b}\\n\")\n",
    "    md.append(fmt_genes(drv_down, \"DOWN\"))\n",
    "\n",
    "    (pre.with_suffix(\".summary.md\")).write_text(\"\\n\".join(md), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"[OK] {contrast} ->\")\n",
    "    print(\"   \", pre.with_suffix(\".summary.md\").name,\n",
    "          pre.with_suffix(\".top_pathways_UP.csv\").name,\n",
    "          pre.with_suffix(\".top_pathways_DOWN.csv\").name,\n",
    "          pre.with_suffix(\".top_genes_UP.csv\").name,\n",
    "          pre.with_suffix(\".top_genes_DOWN.csv\").name)\n",
    "\n",
    "# Global compact sheet across all contrasts\n",
    "if overview_all:\n",
    "    pd.DataFrame(overview_all).sort_values(\n",
    "        [\"contrast\",\"direction\",\"FDR_q\",\"NES\"],\n",
    "        ascending=[True, True, True, False]\n",
    "    ).to_csv(OUT_DIR / \"compact_pathway_overview_all.csv\", index=False)\n",
    "\n",
    "print(\"\\n[OK] Wrote compact summaries to:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a2693-272b-48a6-8410-6417ed2c0eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gsea)",
   "language": "python",
   "name": "gsea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
