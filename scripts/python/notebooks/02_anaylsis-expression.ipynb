{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef7e2fca-242a-4010-a065-691aba70ac0c",
   "metadata": {},
   "source": [
    "# path and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e893f55-a8a8-413d-8019-f55624c1bfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Directory structure ready:\n",
      " - Input counts: /storage/users/job37yv/Projects/Franziska_faber/data/processed_data/qc_fractional_counts\n",
      " - Processed data store: /storage/users/job37yv/Projects/Franziska_faber/data/processed_data\n",
      " - Analysis base: /storage/users/job37yv/Projects/Franziska_faber/analysis\n",
      "   - /storage/users/job37yv/Projects/Franziska_faber/analysis/QC\n",
      "   - /storage/users/job37yv/Projects/Franziska_faber/analysis/DE\n",
      "   - /storage/users/job37yv/Projects/Franziska_faber/analysis/GSEA\n",
      "   - /storage/users/job37yv/Projects/Franziska_faber/analysis/ORA\n",
      "   - /storage/users/job37yv/Projects/Franziska_faber/analysis/figures\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# --- Project base ---\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "\n",
    "# --- Input (QC-prepared counts + metadata) ---\n",
    "COUNT_INPUT_DIR = BASE / \"data\" / \"processed_data\" / \"qc_fractional_counts\"\n",
    "\n",
    "# --- Storage for intermediate/cleaned objects (h5ad, merged counts) ---\n",
    "DATA_PROCESSED_DIR = BASE / \"data\" / \"processed_data\"\n",
    "\n",
    "# --- Analysis outputs (all results and plots) ---\n",
    "ANALYSIS_DIR = BASE / \"analysis\"\n",
    "ANALYSIS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Subdirectories for downstream analysis ---\n",
    "QC_DIR   = ANALYSIS_DIR / \"QC\"\n",
    "DE_DIR   = ANALYSIS_DIR / \"DE\"\n",
    "GSEA_DIR = ANALYSIS_DIR / \"GSEA\"\n",
    "ORA_DIR  = ANALYSIS_DIR / \"ORA\"\n",
    "FIG_DIR  = ANALYSIS_DIR / \"figures\"\n",
    "\n",
    "for d in [QC_DIR, DE_DIR, GSEA_DIR, ORA_DIR, FIG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"[OK] Directory structure ready:\")\n",
    "print(\" - Input counts:\", COUNT_INPUT_DIR)\n",
    "print(\" - Processed data store:\", DATA_PROCESSED_DIR)\n",
    "print(\" - Analysis base:\", ANALYSIS_DIR)\n",
    "for d in [QC_DIR, DE_DIR, GSEA_DIR, ORA_DIR, FIG_DIR]:\n",
    "    print(\"   -\", d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13baa6-5b69-40ec-a9c3-8215cc51f029",
   "metadata": {},
   "source": [
    "# Load data and build adata object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ba0c80f-4078-442a-8163-d4c008ac66cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] anndata not available: operands could not be broadcast together with shapes (12,67665) (1,12) \n",
      "You can still proceed with pandas DataFrames `counts` (samples x genes) and `meta`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_896322/799461717.py:38: RuntimeWarning: Mean of empty slice\n",
      "  gmeans = np.exp(np.nanmean(logX, axis=1)); gmeans[gmeans==0] = np.nan\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Project paths (as you specified) ---\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "COUNT_INPUT_DIR     = BASE / \"data\" / \"processed_data\" / \"qc_fractional_counts\"  # contains counts_fractional.tsv + sample_metadata.tsv\n",
    "DATA_PROCESSED_DIR  = BASE / \"data\" / \"processed_data\"\n",
    "ANALYSIS_DIR        = BASE / \"analysis\"\n",
    "H5AD                = DATA_PROCESSED_DIR / \"host_bulk_fractional_counts.h5ad\"\n",
    "\n",
    "# read TSVs written earlier\n",
    "counts_path = COUNT_INPUT_DIR / \"counts_fractional.tsv\"   # samples x genes (raw fractional)\n",
    "meta_path   = COUNT_INPUT_DIR / \"sample_metadata.tsv\"     # sample metadata\n",
    "\n",
    "counts = pd.read_csv(counts_path, sep=\"\\t\", index_col=0)\n",
    "meta   = pd.read_csv(meta_path,   sep=\"\\t\", index_col=0)\n",
    "\n",
    "# align (just in case)\n",
    "counts = counts.loc[meta.index]\n",
    "\n",
    "# build AnnData (if available) and add norm/log1p\n",
    "adata = None\n",
    "try:\n",
    "    import anndata as ad\n",
    "    adata = ad.AnnData(X=counts.values.astype(float))\n",
    "    adata.obs = meta.copy()\n",
    "    adata.var_names = counts.columns.astype(str)\n",
    "    adata.obs_names = counts.index.astype(str)\n",
    "\n",
    "    # layers\n",
    "    adata.layers[\"counts\"] = counts.values.astype(float)\n",
    "\n",
    "    # size-factor normalization (median-of-ratios) for overview\n",
    "    GxS = adata.layers[\"counts\"].T                     # genes x samples\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        logX = np.log(GxS); logX[~np.isfinite(logX)] = np.nan\n",
    "    gmeans = np.exp(np.nanmean(logX, axis=1)); gmeans[gmeans==0] = np.nan\n",
    "    ratios = GxS / gmeans[:, None]\n",
    "    sfs = np.nanmedian(ratios, axis=0); sfs[~np.isfinite(sfs)] = 1.0\n",
    "    norm = adata.layers[\"counts\"] / sfs[None, :]\n",
    "    adata.layers[\"norm\"]  = norm\n",
    "    adata.layers[\"log1p\"] = np.log1p(norm)\n",
    "\n",
    "    adata.uns[\"counts_type\"] = \"featureCounts fractional (-M --fraction)\"\n",
    "    adata.uns[\"notes\"] = \"Built from merged TSVs (qc_fractional_counts). layers: counts/norm/log1p.\"\n",
    "\n",
    "    DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    adata.write_h5ad(H5AD)\n",
    "    print(\"[OK] AnnData rebuilt from TSVs and saved to:\", H5AD)\n",
    "    print(adata)\n",
    "except Exception as e:\n",
    "    print(\"[WARN] anndata not available:\", e)\n",
    "    print(\"You can still proceed with pandas DataFrames `counts` (samples x genes) and `meta`.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8090bd1-a97a-4c06-bb32-b9039cb136d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9238577a-d475-42ca-8967-acb3392db64f",
   "metadata": {},
   "source": [
    "# map your Geneid → symbols (for GSEA/ORA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ef0e639-3b2c-446b-b83c-248d3feb3176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_ensembl_mappings(adata_ens, species=\"human\"):\n",
    "    \"\"\"\n",
    "    Build dictionaries:\n",
    "      - ensembl (with version) → entrez (NCBI Gene ID)\n",
    "      - ensembl (with version) → uniprot (Swiss-Prot accession)\n",
    "    \"\"\"\n",
    "    ids = pd.Index(adata_ens.var_names.astype(str))\n",
    "\n",
    "    # --- strip version suffix (e.g., ENSG00000141562.13 → ENSG00000141562) ---\n",
    "    ensembl_core = ids.str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "\n",
    "    try:\n",
    "        import mygene\n",
    "        mg = mygene.MyGeneInfo()\n",
    "\n",
    "        q = mg.querymany(\n",
    "            ensembl_core.tolist(),\n",
    "            scopes=\"ensembl.gene\",\n",
    "            fields=\"entrezgene,uniprot.Swiss-Prot\",\n",
    "            species=species,\n",
    "            as_dataframe=True,\n",
    "            returnall=False,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        if not isinstance(q, pd.DataFrame) or q.empty:\n",
    "            print(\"[WARN] mygene returned nothing.\")\n",
    "            return {}, {}\n",
    "\n",
    "        # Clean results\n",
    "        df = q.reset_index().rename(columns={\"query\": \"ensembl_core\"})\n",
    "        df = df.drop_duplicates(\"ensembl_core\")\n",
    "\n",
    "        # Build mapping back to *original IDs with version*\n",
    "        core2ver = pd.Series(ids.values, index=ensembl_core.values)\n",
    "\n",
    "        ens2entrez = {}\n",
    "        ens2uniprot = {}\n",
    "        for _, row in df.iterrows():\n",
    "            ens_core = row[\"ensembl_core\"]\n",
    "            ens_ver  = core2ver.get(ens_core)   # restore versioned ID\n",
    "            if ens_ver is None:\n",
    "                continue\n",
    "            ens2entrez[ens_ver]  = row.get(\"entrezgene\")\n",
    "            ens2uniprot[ens_ver] = row.get(\"uniprot.Swiss-Prot\")\n",
    "\n",
    "        print(f\"[MAP] {len(ens2entrez)} Ensembl IDs mapped to Entrez/UniProt \"\n",
    "              f\"(of {len(ids)} input).\")\n",
    "        return ens2entrez, ens2uniprot\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] mapping failed ({e}); returning empty dicts.\")\n",
    "        return {}, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "419c5017-5b0c-41bd-8b89-e72ab7169c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input sequence provided is already in string format. No operation performed\n",
      "Input sequence provided is already in string format. No operation performed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] kept 67016/67665 features (Ensembl only).\n",
      "[ANN] mapped 50135/67016 features to symbols.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensembl_core</th>\n",
       "      <th>gene_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000223972.5</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>DDX11L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000227232.5</th>\n",
       "      <td>ENSG00000227232</td>\n",
       "      <td>WASH7P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000278267.1</th>\n",
       "      <td>ENSG00000278267</td>\n",
       "      <td>MIR6859-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000243485.5</th>\n",
       "      <td>ENSG00000243485</td>\n",
       "      <td>MIR1302-2HG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000284332.1</th>\n",
       "      <td>ENSG00000284332</td>\n",
       "      <td>MIR1302-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ensembl_core  gene_symbol\n",
       "ENSG00000223972.5  ENSG00000223972      DDX11L1\n",
       "ENSG00000227232.5  ENSG00000227232       WASH7P\n",
       "ENSG00000278267.1  ENSG00000278267    MIR6859-1\n",
       "ENSG00000243485.5  ENSG00000243485  MIR1302-2HG\n",
       "ENSG00000284332.1  ENSG00000284332    MIR1302-2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_ens = filter_and_annotate_ensembl(adata, species=\"human\")  # or \"mouse\"\n",
    "adata_ens.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e5ad382-ff65-430b-b340-4bd60cbd0a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENSG00000223972.5            DDX11L1\n",
       "ENSG00000227232.5             WASH7P\n",
       "ENSG00000278267.1          MIR6859-1\n",
       "ENSG00000243485.5        MIR1302-2HG\n",
       "ENSG00000284332.1          MIR1302-2\n",
       "                          ...       \n",
       "ENSG00000276017.1    ENSG00000276017\n",
       "ENSG00000278817.1    ENSG00000278817\n",
       "ENSG00000277196.4    ENSG00000277196\n",
       "ENSG00000278625.1       LOC124905334\n",
       "ENSG00000277374.1                 U1\n",
       "Name: gene_symbol, Length: 67016, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_ens.var['gene_symbol']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e9950-6781-450c-b294-5e54831fbc46",
   "metadata": {},
   "source": [
    "## mapping dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87d5d97b-c18f-4e35-96d1-dc130682dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_ensembl_mappings(adata_ens, species=\"human\"):\n",
    "    \"\"\"\n",
    "    Build dictionaries:\n",
    "      - ensembl → entrez (NCBI Gene ID)\n",
    "      - ensembl → uniprot (Swiss-Prot accession)\n",
    "    \"\"\"\n",
    "    ids = pd.Index(adata_ens.var_names.astype(str))\n",
    "\n",
    "    try:\n",
    "        import mygene\n",
    "        mg = mygene.MyGeneInfo()\n",
    "\n",
    "        q = mg.querymany(\n",
    "            ids.tolist(),\n",
    "            scopes=\"ensembl.gene\",\n",
    "            fields=\"entrezgene,uniprot.Swiss-Prot\",\n",
    "            species=species,\n",
    "            as_dataframe=True,\n",
    "            returnall=False,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        if not isinstance(q, pd.DataFrame) or q.empty:\n",
    "            print(\"[WARN] mygene returned nothing.\")\n",
    "            return {}, {}\n",
    "\n",
    "        df = q.reset_index().rename(columns={\"query\": \"ensembl\"}).drop_duplicates(\"ensembl\")\n",
    "\n",
    "        # dictionaries\n",
    "        ens2entrez = dict(zip(df[\"ensembl\"], df.get(\"entrezgene\", [None]*len(df))))\n",
    "        ens2uniprot = dict(zip(df[\"ensembl\"], df.get(\"uniprot.Swiss-Prot\", [None]*len(df))))\n",
    "\n",
    "        print(f\"[MAP] {len(ens2entrez)} Ensembl IDs mapped to Entrez and UniProt.\")\n",
    "        return ens2entrez, ens2uniprot\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] mapping failed ({e}); returning empty dicts.\")\n",
    "        return {}, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "220a026f-bffa-48fb-969b-448d82b3644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input sequence provided is already in string format. No operation performed\n",
      "Input sequence provided is already in string format. No operation performed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAP] 67016 Ensembl IDs mapped to Entrez/UniProt (of 67016 input).\n"
     ]
    }
   ],
   "source": [
    "ens2entrez, ens2uniprot = build_ensembl_mappings(adata_ens, species=\"human\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07082c02-b633-463c-9a3f-0ce841acd002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP53 Entrez ID (with version): None\n",
      "TP53 Entrez ID (no version): 7157\n"
     ]
    }
   ],
   "source": [
    "# also create versionless lookup\n",
    "ens2entrez_core = {k.split(\".\")[0]: v for k, v in ens2entrez.items()}\n",
    "ens2uniprot_core = {k.split(\".\")[0]: v for k, v in ens2uniprot.items()}\n",
    "\n",
    "# now both will work\n",
    "print(\"TP53 Entrez ID (with version):\", ens2entrez.get(\"ENSG00000141510.12\"))\n",
    "print(\"TP53 Entrez ID (no version):\", ens2entrez_core.get(\"ENSG00000141510\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c54e7341-ff59-4b92-a4a8-11dec4120cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ENSG00000278267.1': '102466751', 'ENSG00000284332.1': '100302278', 'ENSG00000237613.2': '645520', 'ENSG00000268020.3': '79504', 'ENSG00000240361.2': '403263'}\n",
      "{'ENSG00000186092.6': 'Q8NH21', 'ENSG00000284733.1': 'Q6IEY1', 'ENSG00000284662.1': 'Q6IEY1', 'ENSG00000187634.12': 'Q96NU1', 'ENSG00000188976.11': 'Q9Y3T9'}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "ens2entrez  = {k: v for k, v in ens2entrez.items() if v is not None and not (isinstance(v, float) and math.isnan(v))}\n",
    "ens2uniprot = {k: v for k, v in ens2uniprot.items() if v is not None and not (isinstance(v, float) and math.isnan(v))}\n",
    "\n",
    "print(dict(list(ens2entrez.items())[:5]))\n",
    "print(dict(list(ens2uniprot.items())[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2d9d0c42-4145-475d-add7-d9f2278e6357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ENSG00000278267.1': '102466751', 'ENSG00000284332.1': '100302278', 'ENSG00000237613.2': '645520', 'ENSG00000268020.3': '79504', 'ENSG00000240361.2': '403263', 'ENSG00000186092.6': '79501', 'ENSG00000233750.3': '100420257', 'ENSG00000222623.1': '124906683', 'ENSG00000273874.1': '102465909', 'ENSG00000228463.10': '728481'}\n",
      "{'ENSG00000186092.6': 'Q8NH21', 'ENSG00000284733.1': 'Q6IEY1', 'ENSG00000284662.1': 'Q6IEY1', 'ENSG00000187634.12': 'Q96NU1', 'ENSG00000188976.11': 'Q9Y3T9', 'ENSG00000187961.14': 'Q6TDP4', 'ENSG00000187583.11': 'Q494U1', 'ENSG00000187642.9': 'Q5SV97', 'ENSG00000188290.11': 'Q9HCC6', 'ENSG00000187608.10': 'P05161'}\n"
     ]
    }
   ],
   "source": [
    "# filter out None/NaN/empty\n",
    "ens2entrez  = {k: v for k, v in ens2entrez.items() if v is not None and str(v) != \"nan\"}\n",
    "ens2uniprot = {k: v for k, v in ens2uniprot.items() if v not in [None, [], \"nan\"]}\n",
    "\n",
    "# print first 5 entries\n",
    "print(dict(list(ens2entrez.items())[:10]))\n",
    "print(dict(list(ens2uniprot.items())[:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "826776ae-ba70-49f7-a1f9-fb309a1b56e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 12 × 67016\n",
       "    obs: 'condition', 'tissue', 'replicate'\n",
       "    var: 'ensembl_core', 'gene_symbol'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e33c8c06-655d-40a4-8d62-e2302dacdac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample\n",
       "B_theta_AT_bio1           Bt\n",
       "B_theta_AT_bio2           Bt\n",
       "B_theta_AT_bio3           Bt\n",
       "C_diff_AT_bio1            Cd\n",
       "C_diff_AT_bio2            Cd\n",
       "C_diff_AT_bio3            Cd\n",
       "Co_colonized_AT_bio1      Co\n",
       "Co_colonized_AT_bio2      Co\n",
       "Co_colonized_AT_bio3      Co\n",
       "mock_AT_bio1            Mock\n",
       "mock_AT_bio2            Mock\n",
       "mock_AT_bio3            Mock\n",
       "Name: condition, dtype: category\n",
       "Categories (4, object): ['Bt', 'Cd', 'Co', 'Mock']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_ens.obs['condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee260fc2-5d12-4700-b0b9-d37bdce9fdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample\n",
       "B_theta_AT_bio1         bio1\n",
       "B_theta_AT_bio2         bio2\n",
       "B_theta_AT_bio3         bio3\n",
       "C_diff_AT_bio1          bio1\n",
       "C_diff_AT_bio2          bio2\n",
       "C_diff_AT_bio3          bio3\n",
       "Co_colonized_AT_bio1    bio1\n",
       "Co_colonized_AT_bio2    bio2\n",
       "Co_colonized_AT_bio3    bio3\n",
       "mock_AT_bio1            bio1\n",
       "mock_AT_bio2            bio2\n",
       "mock_AT_bio3            bio3\n",
       "Name: replicate, dtype: category\n",
       "Categories (3, object): ['bio1', 'bio2', 'bio3']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_ens.obs['replicate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cac008-a4a4-4c56-9877-0a954fc9117d",
   "metadata": {},
   "source": [
    "## save objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8690c9ad-7524-437b-a11d-aac39d6e28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import anndata as ad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d561cc77-b23c-4ed3-a1fe-647736d1cb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved Ensembl-filtered AnnData → /storage/users/job37yv/Projects/Franziska_faber/data/processed_data/host_bulk_fractional_counts_ensembl.h5ad\n",
      "[OK] Saved mapping dictionaries → /storage/users/job37yv/Projects/Franziska_faber/data/processed_data/ensembl_mappings.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- paths ---\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "DATA_PROCESSED_DIR = BASE / \"data\" / \"processed_data\"\n",
    "DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "H5AD_OUT   = DATA_PROCESSED_DIR / \"host_bulk_fractional_counts_ensembl.h5ad\"\n",
    "DICT_OUT   = DATA_PROCESSED_DIR / \"ensembl_mappings.pkl\"\n",
    "\n",
    "# --- save AnnData with only Ensembl features ---\n",
    "adata_ens.write_h5ad(H5AD_OUT)\n",
    "print(f\"[OK] Saved Ensembl-filtered AnnData → {H5AD_OUT}\")\n",
    "\n",
    "# --- save dictionaries ---\n",
    "with open(DICT_OUT, \"wb\") as f:\n",
    "    pickle.dump({\"ens2entrez\": ens2entrez, \"ens2uniprot\": ens2uniprot}, f)\n",
    "print(f\"[OK] Saved mapping dictionaries → {DICT_OUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ef8d514e-ca72-4021-8484-b1ab6b03709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 12 × 67016\n",
       "    obs: 'condition', 'tissue', 'replicate'\n",
       "    var: 'ensembl_core', 'gene_symbol'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "78c737b4-d6d4-42e5-bfe3-63d62212a8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ENSG00000223972.5', 'ENSG00000227232.5', 'ENSG00000278267.1',\n",
       "       'ENSG00000243485.5', 'ENSG00000284332.1', 'ENSG00000237613.2',\n",
       "       'ENSG00000268020.3', 'ENSG00000240361.2', 'ENSG00000186092.6',\n",
       "       'ENSG00000238009.6',\n",
       "       ...\n",
       "       'ENSG00000273739.1', 'ENSG00000276700.1', 'ENSG00000276312.1',\n",
       "       'ENSG00000275757.1', 'ENSG00000278573.1', 'ENSG00000276017.1',\n",
       "       'ENSG00000278817.1', 'ENSG00000277196.4', 'ENSG00000278625.1',\n",
       "       'ENSG00000277374.1'],\n",
       "      dtype='object', length=67016)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_ens.var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa71f1-ef72-41ba-b373-ff1932322fad",
   "metadata": {},
   "source": [
    "## reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d55d7de7-448a-42b6-b11f-9a5e9b3e7ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP53 Entrez ID: None\n",
      "TP53 UniProt: None\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import pickle\n",
    "\n",
    "# load AnnData\n",
    "adata_ens = ad.read_h5ad(H5AD_OUT)\n",
    "\n",
    "# load dictionaries\n",
    "with open(DICT_OUT, \"rb\") as f:\n",
    "    maps = pickle.load(f)\n",
    "\n",
    "ens2entrez = maps[\"ens2entrez\"]\n",
    "ens2uniprot = maps[\"ens2uniprot\"]\n",
    "\n",
    "print(\"TP53 Entrez ID:\", ens2entrez.get(\"ENSG00000141510\"))\n",
    "print(\"TP53 UniProt:\", ens2uniprot.get(\"ENSG00000141510\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7098da-bf03-42f8-b858-e2e4c36e3110",
   "metadata": {},
   "source": [
    "# Differential expression (Python-only DE (voom-style WLS; handles fractional counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41991d22-653f-490c-b49a-7a18323563b1",
   "metadata": {},
   "source": [
    "## Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81c4cfac-4c40-4257-99b3-2c81f72f1f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Samples per condition:\n",
      "condition\n",
      "Mock    3\n",
      "Bt      3\n",
      "Cd      3\n",
      "Co      3\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/job37yv/miniforge3/envs/scAnalysis/lib/python3.10/site-packages/statsmodels/nonparametric/smoothers_lowess.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  res, _ = _lowess(y, x, x, np.ones_like(x),\n",
      "/tmp/ipykernel_896322/4171479770.py:108: RuntimeWarning: divide by zero encountered in divide\n",
      "  t_g = beta / se_g\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Wrote /storage/users/job37yv/Projects/Franziska_faber/analysis/DE/python_voomlite_Bt_vs_Mock.csv\n",
      "[ok] Wrote /storage/users/job37yv/Projects/Franziska_faber/analysis/DE/python_voomlite_Cd_vs_Mock.csv\n",
      "[ok] Wrote /storage/users/job37yv/Projects/Franziska_faber/analysis/DE/python_voomlite_Co_vs_Mock.csv\n",
      "[ok] Wrote /storage/users/job37yv/Projects/Franziska_faber/analysis/DE/python_voomlite_Bt_vs_Cd.csv\n",
      "[ok] Wrote /storage/users/job37yv/Projects/Franziska_faber/analysis/DE/python_voomlite_Bt_vs_Co.csv\n",
      "[ok] Wrote /storage/users/job37yv/Projects/Franziska_faber/analysis/DE/python_voomlite_Cd_vs_Co.csv\n",
      "[ok] Summary -> /storage/users/job37yv/Projects/Franziska_faber/analysis/DE/python_voomlite_summary.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ---------- Inputs ----------\n",
    "# Expect: adata_ens with layers[\"counts\"], obs[\"condition\"] in {Bt, Cd, Co, Mock}\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "DE_DIR = BASE / \"analysis\" / \"DE\"\n",
    "DE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "layer = \"counts\"\n",
    "assert layer in adata_ens.layers, f\"Missing layer '{layer}'. Available: {list(adata_ens.layers.keys())}\"\n",
    "\n",
    "# counts: genes x samples\n",
    "counts = pd.DataFrame(\n",
    "    adata_ens.layers[layer],\n",
    "    index=adata_ens.obs_names,   # samples\n",
    "    columns=adata_ens.var_names  # genes\n",
    ").T\n",
    "\n",
    "meta = adata_ens.obs.loc[counts.columns].copy()\n",
    "cond = meta[\"condition\"].astype(\"category\")\n",
    "if \"Mock\" not in cond.cat.categories:\n",
    "    raise ValueError(\"Reference 'Mock' not in condition.\")\n",
    "# Put Mock first for intuitive contrasts\n",
    "cond = cond.cat.reorder_categories([\"Mock\"] + [c for c in cond.cat.categories if c != \"Mock\"], ordered=True)\n",
    "meta[\"condition\"] = cond\n",
    "\n",
    "print(\"[info] Samples per condition:\")\n",
    "print(meta[\"condition\"].value_counts())\n",
    "\n",
    "# ---------- Normalization: library-size CPM then log ----------\n",
    "lib_sizes = counts.sum(axis=0).values  # per-sample library sizes\n",
    "lib_sizes[lib_sizes == 0] = 1.0\n",
    "cpm = counts.div(lib_sizes, axis=1) * 1e6\n",
    "\n",
    "# Add a small offset to stabilize logs for low counts (as voom does via prior.count)\n",
    "prior_count = 0.5\n",
    "logCPM = np.log2(cpm + prior_count)\n",
    "\n",
    "# ---------- Design matrix (no intercept: columns per level) ----------\n",
    "X = pd.get_dummies(meta[\"condition\"], drop_first=False)  # columns: Mock, Bt, Cd, Co\n",
    "# We’ll compute contrasts manually below.\n",
    "X_mat = X.values\n",
    "\n",
    "# ---------- voom-like weights ----------\n",
    "# Estimate mean–variance trend of logCPM:\n",
    "# 1) mean expression per gene (across samples)\n",
    "mu = logCPM.mean(axis=1).values  # (G,)\n",
    "# 2) residual variance per gene across samples\n",
    "#    Start with unweighted variance as a first pass\n",
    "sigma2_gene = logCPM.var(axis=1, ddof=1).values  # (G,)\n",
    "\n",
    "# LOWESS: predict variance as a smooth function of mean\n",
    "# guard: remove NaNs/Infs\n",
    "ok = np.isfinite(mu) & np.isfinite(sigma2_gene)\n",
    "fit = lowess(sigma2_gene[ok], mu[ok], frac=0.3, return_sorted=True)\n",
    "mu_grid, var_smooth = fit[:,0], fit[:,1]\n",
    "\n",
    "# Map each gene's mu to a smoothed variance via nearest neighbor on the grid\n",
    "# (simple & fast; spline would be nicer but overkill)\n",
    "order = np.argsort(mu_grid)\n",
    "mu_sorted = mu_grid[order]\n",
    "var_sorted = np.maximum(var_smooth[order], 1e-6)\n",
    "idx = np.searchsorted(mu_sorted, mu)\n",
    "idx = np.clip(idx, 0, len(mu_sorted)-1)\n",
    "var_hat_gene = var_sorted[idx]  # (G,)\n",
    "\n",
    "# Turn gene-level variance into observation-level precision weights:\n",
    "# simplest choice: w_gs = 1 / var_hat_gene for all samples s of gene g\n",
    "weights = (1.0 / var_hat_gene)[:, None] * np.ones_like(logCPM.values)\n",
    "\n",
    "# ---------- Fit per-gene weighted least squares ----------\n",
    "Y = logCPM.values  # (G x N)\n",
    "\n",
    "# Precompute (X' W X)^{-1} per gene efficiently:\n",
    "# Because W is diagonal (weights per sample), we can scale X and y by sqrt(w)\n",
    "sqrtW = np.sqrt(weights)  # (G x N)\n",
    "\n",
    "coef = []\n",
    "se = []\n",
    "tval = []\n",
    "df_resid = Y.shape[1] - X_mat.shape[1]\n",
    "\n",
    "# Precompute X once per gene with weights\n",
    "for g in range(Y.shape[0]):\n",
    "    y = Y[g, :] * sqrtW[g, :]\n",
    "    Xw = X_mat * sqrtW[g, :][:, None]\n",
    "    XtX = Xw.T @ Xw\n",
    "    try:\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # fallback: pseudo-inverse if singular\n",
    "        XtX_inv = np.linalg.pinv(XtX)\n",
    "    beta = XtX_inv @ (Xw.T @ y)\n",
    "    # residuals\n",
    "    yhat = X_mat @ beta\n",
    "    resid = (Y[g, :] - yhat)\n",
    "    # weighted residual variance (sigma^2)\n",
    "    # Using weights: sum(w * e^2)/(N - p)\n",
    "    sig2 = np.sum(weights[g, :] * resid**2) / max(df_resid, 1)\n",
    "    # standard errors of coefficients\n",
    "    covb = sig2 * XtX_inv\n",
    "    se_g = np.sqrt(np.diag(covb))\n",
    "    t_g = beta / se_g\n",
    "    coef.append(beta)\n",
    "    se.append(se_g)\n",
    "    tval.append(t_g)\n",
    "\n",
    "coef = np.vstack(coef)  # (G x P)\n",
    "se   = np.vstack(se)    # (G x P)\n",
    "tval = np.vstack(tval)  # (G x P)\n",
    "\n",
    "# Columns of X (and coef) are in this order:\n",
    "coef_cols = list(X.columns)  # ['Mock','Bt','Cd','Co']\n",
    "\n",
    "# ---------- Define contrasts ----------\n",
    "# Each contrast is a vector c over columns [Mock, Bt, Cd, Co]\n",
    "def contrast_vec(name):\n",
    "    m = {col:i for i,col in enumerate(coef_cols)}\n",
    "    if name == \"Bt_vs_Mock\":\n",
    "        c = np.zeros(len(coef_cols)); c[m[\"Bt\"]]  = 1; c[m[\"Mock\"]] = -1\n",
    "    elif name == \"Cd_vs_Mock\":\n",
    "        c = np.zeros(len(coef_cols)); c[m[\"Cd\"]]  = 1; c[m[\"Mock\"]] = -1\n",
    "    elif name == \"Co_vs_Mock\":\n",
    "        c = np.zeros(len(coef_cols)); c[m[\"Co\"]]  = 1; c[m[\"Mock\"]] = -1\n",
    "    elif name == \"Bt_vs_Cd\":\n",
    "        c = np.zeros(len(coef_cols)); c[m[\"Bt\"]]  = 1; c[m[\"Cd\"]]   = -1\n",
    "    elif name == \"Bt_vs_Co\":\n",
    "        c = np.zeros(len(coef_cols)); c[m[\"Bt\"]]  = 1; c[m[\"Co\"]]   = -1\n",
    "    elif name == \"Cd_vs_Co\":\n",
    "        c = np.zeros(len(coef_cols)); c[m[\"Cd\"]]  = 1; c[m[\"Co\"]]   = -1\n",
    "    else:\n",
    "        raise ValueError(name)\n",
    "    return c\n",
    "\n",
    "contrasts = [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\",\"Bt_vs_Cd\",\"Bt_vs_Co\",\"Cd_vs_Co\"]\n",
    "\n",
    "# For each contrast, compute:\n",
    "#   logFC = c' * beta\n",
    "#   SE(logFC) = sqrt(c' * Cov(beta) * c)\n",
    "# where Cov(beta) ≈ average across genes? Better: use each gene's covb via sig2*XtX_inv computed above.\n",
    "# We didn't keep per-gene covb but we can recompute SE from se & XtX_inv — to keep it lightweight,\n",
    "# estimate SE via delta method using per-gene XtX_inv and sigma^2 already embedded in se.\n",
    "# Since we don't store XtX_inv per gene, recompute quickly inside loop.\n",
    "\n",
    "results = {}\n",
    "gene_names = counts.index.to_numpy()\n",
    "\n",
    "# Precompute per-gene XtX_inv and sigma^2 again (cheap)\n",
    "XtX_inv_all = []\n",
    "sigma2_all = []\n",
    "for g in range(Y.shape[0]):\n",
    "    y = Y[g, :] * sqrtW[g, :]\n",
    "    Xw = X_mat * sqrtW[g, :][:, None]\n",
    "    XtX = Xw.T @ Xw\n",
    "    try:\n",
    "        XtX_inv = np.linalg.inv(XtX)\n",
    "    except np.linalg.LinAlgError:\n",
    "        XtX_inv = np.linalg.pinv(XtX)\n",
    "    yhat = X_mat @ (XtX_inv @ (Xw.T @ y))\n",
    "    resid = (Y[g, :] - yhat)\n",
    "    sig2 = np.sum(weights[g, :] * resid**2) / max(df_resid, 1)\n",
    "    XtX_inv_all.append(XtX_inv)\n",
    "    sigma2_all.append(sig2)\n",
    "XtX_inv_all = np.array(XtX_inv_all)  # (G x P x P)\n",
    "sigma2_all = np.array(sigma2_all)    # (G,)\n",
    "\n",
    "for name in contrasts:\n",
    "    c = contrast_vec(name)\n",
    "    # contrast estimate per gene\n",
    "    logFC = coef @ c\n",
    "    # SE via sqrt( sigma^2 * c' (XtX)^-1 c )\n",
    "    # vectorized:\n",
    "    c_col = c.reshape(-1,1)\n",
    "    tmp = XtX_inv_all @ c_col        # (G x P x 1)\n",
    "    c_var = (c.reshape(1,1,-1) @ XtX_inv_all @ c_col).reshape(-1)  # (G,)\n",
    "    se_contrast = np.sqrt(np.maximum(sigma2_all * c_var, 1e-12))\n",
    "    t = logFC / se_contrast\n",
    "    # two-sided p-values from t with df_resid\n",
    "    from scipy.stats import t as student_t\n",
    "    pval = 2 * (1 - student_t.cdf(np.abs(t), df=df_resid))\n",
    "    padj = multipletests(pval, method=\"fdr_bh\")[1]\n",
    "\n",
    "    # AveExpr as average logCPM per gene\n",
    "    ave_expr = logCPM.mean(axis=1).values\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"gene\": gene_names,\n",
    "        \"logFC\": logFC,\n",
    "        \"AveExpr\": ave_expr,\n",
    "        \"t\": t,\n",
    "        \"pval\": pval,\n",
    "        \"padj\": padj\n",
    "    })\n",
    "    # insert gene_symbol if present\n",
    "    if \"gene_symbol\" in adata_ens.var.columns:\n",
    "        gene_map = pd.Series(adata_ens.var[\"gene_symbol\"].astype(str).values,\n",
    "                             index=adata_ens.var_names.astype(str))\n",
    "        df.insert(1, \"gene_symbol\", gene_map.reindex(df[\"gene\"]).values)\n",
    "\n",
    "    out = DE_DIR / f\"python_voomlite_{name}.csv\"\n",
    "    df.sort_values(\"pval\", inplace=True)\n",
    "    df.to_csv(out, index=False)\n",
    "    results[name] = df\n",
    "    print(f\"[ok] Wrote {out}\")\n",
    "\n",
    "# (optional) quick summary\n",
    "summary = []\n",
    "for k, df in results.items():\n",
    "    sig = df[df[\"padj\"] < 0.05]\n",
    "    sig_lfc1 = sig[sig[\"logFC\"].abs() >= 1]\n",
    "    summary.append({\n",
    "        \"contrast\": k,\n",
    "        \"n_sig_FDR<0.05\": len(sig),\n",
    "        \"n_sig_|logFC|>=1\": len(sig_lfc1),\n",
    "        \"up_FDR<0.05\": (sig[\"logFC\"] > 0).sum(),\n",
    "        \"down_FDR<0.05\": (sig[\"logFC\"] < 0).sum()\n",
    "    })\n",
    "pd.DataFrame(summary).to_csv(DE_DIR / \"python_voomlite_summary.csv\", index=False)\n",
    "print(\"[ok] Summary ->\", DE_DIR / \"python_voomlite_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc13602-0c73-45f4-a3f0-7b820e3e353d",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e573408-4d16-4d00-97f5-8081d98692ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote volcano plots and correlation heatmap to /storage/users/job37yv/Projects/Franziska_faber/analysis/figures\n",
      "[OK] Wrote clustered top-union heatmap with dendrograms to /storage/users/job37yv/Projects/Franziska_faber/analysis/figures/heatmap_top_union_clustered.png\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, leaves_list\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# --- Paths & inputs ---\n",
    "BASE = Path(\"/storage/users/job37yv/Projects/Franziska_faber\")\n",
    "ANALYSIS_DIR = BASE / \"analysis\"\n",
    "DE_DIR  = ANALYSIS_DIR / \"DE\"\n",
    "FIG_DIR = ANALYSIS_DIR / \"figures\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "contrasts = [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\",\"Bt_vs_Cd\",\"Bt_vs_Co\",\"Cd_vs_Co\"]\n",
    "res = {c: pd.read_csv(DE_DIR / f\"python_voomlite_{c}.csv\") for c in contrasts}\n",
    "for c in contrasts:\n",
    "    res[c][\"gene\"] = res[c][\"gene\"].astype(str)\n",
    "\n",
    "# Universe of tested genes (intersection across contrasts)\n",
    "gene_universe = set.intersection(*[set(df[\"gene\"]) for df in res.values()])\n",
    "\n",
    "# --- Volcano plots ---\n",
    "def volcano_plot(df, title, outpath, padj_thr=0.05, lfc_thr=1.0):\n",
    "    x = df[\"logFC\"].values\n",
    "    y = -np.log10(np.clip(df[\"pval\"].values, 1e-300, 1.0))\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.scatter(x, y, s=6, alpha=0.4)\n",
    "    mask = (df[\"padj\"] < padj_thr) & (np.abs(df[\"logFC\"]) >= lfc_thr)\n",
    "    plt.scatter(df.loc[mask, \"logFC\"], -np.log10(np.clip(df.loc[mask, \"pval\"], 1e-300, 1.0)), s=6)\n",
    "    plt.axvline(-lfc_thr, linestyle=\"--\"); plt.axvline(lfc_thr, linestyle=\"--\")\n",
    "    plt.axhline(-np.log10(padj_thr), linestyle=\"--\")\n",
    "    plt.xlabel(\"log2 Fold Change\"); plt.ylabel(\"-log10 p-value\")\n",
    "    plt.title(f\"Volcano: {title}\")\n",
    "    plt.tight_layout(); plt.savefig(outpath, dpi=160); plt.close()\n",
    "\n",
    "for c in contrasts:\n",
    "    volcano_plot(res[c], c, FIG_DIR / f\"volcano_{c}.png\")\n",
    "\n",
    "# --- logFC correlation heatmap across contrasts ---\n",
    "genes_sorted = sorted(gene_universe)\n",
    "M = np.vstack([res[c].set_index(\"gene\").loc[genes_sorted, \"logFC\"].values for c in contrasts])\n",
    "corr = np.corrcoef(M)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(corr, interpolation=\"nearest\")\n",
    "plt.xticks(range(len(contrasts)), contrasts, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(contrasts)), contrasts)\n",
    "plt.colorbar(label=\"Pearson r\")\n",
    "plt.title(\"logFC correlation across contrasts\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"corr_logFC_all.png\", dpi=160); plt.close()\n",
    "\n",
    "# --- Clustered heatmap of top-union genes (rows & columns dendrograms) ---\n",
    "# Recompute logCPM for plotting (same transform used in DE)\n",
    "counts = pd.DataFrame(\n",
    "    adata_ens.layers[\"counts\"],\n",
    "    index=adata_ens.obs_names,   # samples\n",
    "    columns=adata_ens.var_names  # genes (Ensembl IDs, may include version)\n",
    ").T\n",
    "lib_sizes = counts.sum(axis=0).values\n",
    "lib_sizes[lib_sizes == 0] = 1.0\n",
    "cpm = counts.div(lib_sizes, axis=1) * 1e6\n",
    "logCPM = np.log2(cpm + 0.5)\n",
    "\n",
    "# Top union = top 50 per vs-Mock contrast\n",
    "top_union = set()\n",
    "for c in [\"Bt_vs_Mock\",\"Cd_vs_Mock\",\"Co_vs_Mock\"]:\n",
    "    df = res[c].sort_values([\"padj\",\"pval\",\"logFC\"], ascending=[True, True, False])\n",
    "    top_union.update(df[\"gene\"].head(50).tolist())\n",
    "sel_genes = [g for g in top_union if g in logCPM.index]\n",
    "\n",
    "# --- robust Ensembl (±version) -> gene symbol mapping\n",
    "def strip_ver(x: str) -> str:\n",
    "    return re.sub(r\"\\.\\d+$\", \"\", x)\n",
    "\n",
    "# Prefer 'gene_symbol', fall back to 'gene_symbols'\n",
    "sym_col = \"gene_symbol\" if \"gene_symbol\" in adata_ens.var.columns else (\n",
    "          \"gene_symbols\" if \"gene_symbols\" in adata_ens.var.columns else None)\n",
    "\n",
    "if len(sel_genes) > 0:\n",
    "    # Build a mapping keyed by *core* Ensembl ID (no version)\n",
    "    if sym_col is not None:\n",
    "        # If you already keep stripped IDs in var['ensembl_core'], use that; else strip var_names.\n",
    "        if \"ensembl_core\" in adata_ens.var.columns:\n",
    "            core_index = adata_ens.var[\"ensembl_core\"].astype(str).values\n",
    "        else:\n",
    "            core_index = pd.Index(adata_ens.var_names.astype(str)).map(strip_ver).values\n",
    "        ens_to_sym = pd.Series(\n",
    "            adata_ens.var[sym_col].astype(str).values,\n",
    "            index=core_index\n",
    "        )\n",
    "    else:\n",
    "        ens_to_sym = None  # no symbols available\n",
    "\n",
    "    sel_genes_core = [strip_ver(g) for g in sel_genes]\n",
    "    row_labels_all = [ens_to_sym.get(core, core) if ens_to_sym is not None else core\n",
    "                      for core in sel_genes_core]\n",
    "\n",
    "    # Matrix & z-score per gene\n",
    "    Z = logCPM.loc[sel_genes]\n",
    "    Z = (Z - Z.mean(axis=1).values[:, None]) / (Z.std(axis=1).values[:, None] + 1e-9)\n",
    "\n",
    "    # Cluster rows (euclidean, ward) and columns (correlation distance, average)\n",
    "    row_link  = linkage(pdist(Z.values, metric=\"euclidean\"), method=\"ward\")\n",
    "    row_order = leaves_list(row_link)\n",
    "\n",
    "    Zt = Z.values.T\n",
    "    C  = np.corrcoef(Zt)\n",
    "    D  = np.clip(1 - C, 0, 2)\n",
    "    col_link  = linkage(squareform(D, checks=False), method=\"average\")\n",
    "    col_order = leaves_list(col_link)\n",
    "\n",
    "    # Reorder matrix & labels\n",
    "    Z_ord      = Z.values[row_order][:, col_order]\n",
    "    row_labels = [row_labels_all[i] for i in row_order]\n",
    "    col_labels = logCPM.columns[col_order]\n",
    "\n",
    "    # Draw dendrogram heatmap\n",
    "    fig = plt.figure(figsize=(max(8, 0.4*len(col_labels)+4),\n",
    "                              max(8, 0.18*len(row_labels)+4)))\n",
    "    top = 0.93; left = 0.22; dendro_h = 0.15; dendro_w = 0.15; heat_w = 0.7; heat_h = 0.7\n",
    "\n",
    "    ax_col = fig.add_axes([left, top - dendro_h, heat_w, dendro_h])\n",
    "    dendrogram(col_link, ax=ax_col, no_labels=True, color_threshold=None)\n",
    "    ax_col.set_xticks([]); ax_col.set_yticks([])\n",
    "\n",
    "    ax_row = fig.add_axes([left - dendro_w, top - dendro_h - heat_h, dendro_w, heat_h])\n",
    "    dendrogram(row_link, ax=ax_row, orientation=\"right\", no_labels=True, color_threshold=None)\n",
    "    ax_row.set_xticks([]); ax_row.set_yticks([])\n",
    "\n",
    "    ax_heat = fig.add_axes([left, top - dendro_h - heat_h, heat_w, heat_h])\n",
    "    im = ax_heat.imshow(Z_ord, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    ax_heat.set_xticks(range(len(col_labels)))\n",
    "    ax_heat.set_xticklabels(col_labels, rotation=90, fontsize=8)\n",
    "    ax_heat.set_yticks(range(len(row_labels)))\n",
    "    ax_heat.set_yticklabels(row_labels, fontsize=7)  # always gene symbols when available\n",
    "    ax_heat.set_title(\"Top-union DE genes (z-scored logCPM)\")\n",
    "\n",
    "    cax = fig.add_axes([left + heat_w + 0.01, top - dendro_h - heat_h, 0.02, heat_h])\n",
    "    cb = plt.colorbar(im, cax=cax); cb.set_label(\"Z-score\")\n",
    "\n",
    "    plt.savefig(FIG_DIR / \"heatmap_top_union_clustered.png\", dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"[OK] Wrote volcano plots and correlation heatmap to\", FIG_DIR)\n",
    "print(\"[OK] Wrote clustered top-union heatmap with dendrograms to\", FIG_DIR / \"heatmap_top_union_clustered.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e349f970-dc4b-44a2-9ef6-6d4f6ec638e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scAnalysis)",
   "language": "python",
   "name": "scanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
